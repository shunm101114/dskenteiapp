import type { Question } from "../types";

export const questions: Question[] = [
  // ===== データサイエンス力（数学・統計） =====
  {
    id: "math-001",
    category: "データサイエンス力",
    question: "正規分布 N(μ, σ²) において、平均μから±1σの範囲に含まれるデータの割合は約何%か？",
    choices: ["約50%", "約68%", "約95%", "約99%"],
    correctIndex: 1,
    explanation:
      "正規分布では、平均±1σに約68.3%、±2σに約95.4%、±3σに約99.7%のデータが含まれます。これは「68-95-99.7ルール」として知られています。",
  },
  {
    id: "math-002",
    category: "データサイエンス力",
    question: "ベイズの定理で、P(A|B) を求める式として正しいものはどれか？",
    choices: [
      "P(B|A) × P(A) / P(B)",
      "P(A) × P(B) / P(B|A)",
      "P(A) + P(B) - P(A∩B)",
      "P(B) × P(A|B) / P(A)",
    ],
    correctIndex: 0,
    explanation:
      "ベイズの定理は P(A|B) = P(B|A) × P(A) / P(B) です。事前確率P(A)と尤度P(B|A)から事後確率P(A|B)を求めることができます。",
  },
  {
    id: "math-003",
    category: "データサイエンス力",
    question: "相関係数の値の範囲として正しいものはどれか？",
    choices: ["0から1", "-1から1", "0から∞", "-∞から∞"],
    correctIndex: 1,
    explanation:
      "ピアソンの相関係数は-1から1の範囲をとります。1に近いほど正の相関、-1に近いほど負の相関、0に近いほど無相関を示します。",
  },
  {
    id: "math-004",
    category: "データサイエンス力",
    question: "中心極限定理の説明として最も適切なものはどれか？",
    choices: [
      "母集団が正規分布に従う場合のみ標本平均も正規分布に従う",
      "標本サイズが十分大きければ、母集団の分布に関わらず標本平均の分布は近似的に正規分布に従う",
      "標本サイズが大きくなるほど標本平均は0に収束する",
      "全てのデータは中心値付近に集まる傾向がある",
    ],
    correctIndex: 1,
    explanation:
      "中心極限定理は、母集団の分布がどのような形であっても、標本サイズnが十分大きければ標本平均の分布が正規分布に近づくという定理です。",
  },
  {
    id: "math-005",
    category: "データサイエンス力",
    question: "第1種の過誤（Type I Error）とは何か？",
    choices: [
      "帰無仮説が偽であるのに棄却しない過ち",
      "帰無仮説が真であるのに棄却してしまう過ち",
      "対立仮説が真であるのに採択しない過ち",
      "検定統計量の計算を間違える過ち",
    ],
    correctIndex: 1,
    explanation:
      "第1種の過誤（αエラー）は、帰無仮説が正しいにもかかわらず棄却してしまう誤りです。有意水準αはこの過誤の確率の上限を決めます。第2種の過誤（βエラー）は帰無仮説が偽なのに棄却しない誤りです。",
  },
  {
    id: "math-006",
    category: "データサイエンス力",
    question: "分散の計算式として正しいものはどれか？（μは平均値）",
    choices: [
      "Σ|xi - μ| / n",
      "Σ(xi - μ)² / n",
      "√(Σ(xi - μ)² / n)",
      "Σ(xi - μ) / n",
    ],
    correctIndex: 1,
    explanation:
      "分散は各データと平均の差（偏差）の2乗の平均です。Σ(xi - μ)² / n で計算します。なお、√をとったものが標準偏差です。",
  },
  {
    id: "math-007",
    category: "データサイエンス力",
    question: "確率変数XとYが独立である場合、V(X+Y) の値はどうなるか？",
    choices: [
      "V(X) + V(Y)",
      "V(X) × V(Y)",
      "V(X) + V(Y) + 2Cov(X,Y)",
      "V(X) - V(Y)",
    ],
    correctIndex: 0,
    explanation:
      "独立な確率変数の和の分散は、各分散の和に等しくなります（V(X+Y) = V(X) + V(Y)）。独立でない場合は共分散の項が加わります。",
  },
  {
    id: "math-008",
    category: "データサイエンス力",
    question: "p値（p-value）の説明として正しいものはどれか？",
    choices: [
      "帰無仮説が正しい確率",
      "対立仮説が正しい確率",
      "帰無仮説が正しいと仮定した場合に、観測データ以上に極端な結果が得られる確率",
      "検定の信頼度を表す割合",
    ],
    correctIndex: 2,
    explanation:
      "p値は帰無仮説の下で、観測されたデータと同じかそれ以上に極端な結果が得られる確率です。p値が有意水準α未満であれば帰無仮説を棄却します。",
  },
  {
    id: "math-009",
    category: "データサイエンス力",
    question: "行列Aの逆行列A⁻¹が存在する条件はどれか？",
    choices: [
      "Aが正方行列である",
      "Aの行列式が0でない",
      "Aの全ての要素が正である",
      "Aが対角行列である",
    ],
    correctIndex: 1,
    explanation:
      "逆行列が存在するためには、行列が正方行列であること、かつ行列式(det(A))が0でないことが必要です。行列式が0の行列を特異行列と呼びます。",
  },
  {
    id: "math-010",
    category: "データサイエンス力",
    question: "最尤推定法の説明として正しいものはどれか？",
    choices: [
      "データの平均値をパラメータの推定値とする方法",
      "観測データが得られる尤度（確率）を最大にするパラメータを求める方法",
      "パラメータの事前分布と事後分布を比較する方法",
      "二乗誤差を最小化するパラメータを求める方法",
    ],
    correctIndex: 1,
    explanation:
      "最尤推定法（MLE）は、与えられたデータが観測される確率（尤度関数）を最大化するパラメータ値を推定値として採用する方法です。",
  },
  {
    id: "math-011",
    category: "データサイエンス力",
    question: "偏微分の説明として正しいものはどれか？",
    choices: [
      "複数の変数を同時に微分する操作",
      "多変数関数において、1つの変数以外を定数とみなして微分する操作",
      "微分の近似値を求める操作",
      "積分の逆演算",
    ],
    correctIndex: 1,
    explanation:
      "偏微分は多変数関数において、注目する1つの変数以外を定数として扱い微分する操作です。機械学習の勾配計算で頻繁に使用されます。",
  },
  {
    id: "math-012",
    category: "データサイエンス力",
    question: "カイ二乗検定の主な用途はどれか？",
    choices: [
      "2群の平均値の差の検定",
      "カテゴリカルデータの独立性や適合度の検定",
      "回帰係数の有意性の検定",
      "分散の等質性の検定",
    ],
    correctIndex: 1,
    explanation:
      "カイ二乗検定はカテゴリカルデータ（名義尺度）に対して、2つの変数間の独立性の検定や、観測度数と期待度数の適合度の検定に使用します。",
  },
  {
    id: "math-013",
    category: "データサイエンス力",
    question: "共分散が正の値を取る場合、2つの変数の関係はどれか？",
    choices: [
      "一方が増加すると他方が減少する傾向",
      "一方が増加すると他方も増加する傾向",
      "2つの変数は独立である",
      "2つの変数に非線形の関係がある",
    ],
    correctIndex: 1,
    explanation:
      "共分散が正の場合、2つの変数は同じ方向に変動する傾向があります。負の場合は逆方向、0に近い場合は線形な関連が弱いことを示します。",
  },
  {
    id: "math-014",
    category: "データサイエンス力",
    question: "標本の不偏分散を求める際に、nではなくn-1で割る理由はどれか？",
    choices: [
      "計算を簡略化するため",
      "母分散の推定値として偏りをなくすため",
      "標本サイズが小さい場合の補正",
      "正規分布に従わせるため",
    ],
    correctIndex: 1,
    explanation:
      "標本分散をnで割ると母分散を過小推定する傾向（偏り）があるため、n-1で割ることで不偏推定量にします。n-1はベッセルの補正と呼ばれます。",
  },
  {
    id: "math-015",
    category: "データサイエンス力",
    question: "ポアソン分布が適用される典型的な場面はどれか？",
    choices: [
      "コインを投げた時の表裏の回数",
      "単位時間あたりに発生する稀な事象の回数",
      "連続量の測定誤差",
      "2群の平均値の比較",
    ],
    correctIndex: 1,
    explanation:
      "ポアソン分布は、単位時間・単位面積あたりに発生する稀な事象の回数をモデル化します。例：1時間あたりの来客数、1ページあたりの誤植数などです。",
  },
  {
    id: "math-016",
    category: "データサイエンス力",
    question: "固有値と固有ベクトルの説明として正しいものはどれか？",
    choices: [
      "行列の対角成分の和とその列ベクトル",
      "行列による線形変換でスカラー倍になるベクトルと、そのスカラー",
      "行列の行列式と逆行列の列ベクトル",
      "行列のランクと零空間の基底",
    ],
    correctIndex: 1,
    explanation:
      "行列Aに対しAv = λvを満たすベクトルvが固有ベクトル、スカラーλが固有値です。PCAでは共分散行列の固有値・固有ベクトルを利用して次元削減を行います。",
  },
  {
    id: "math-017",
    category: "データサイエンス力",
    question: "多重共線性（マルチコリニアリティ）が問題になる分析手法はどれか？",
    choices: [
      "クラスタリング",
      "重回帰分析",
      "主成分分析",
      "決定木",
    ],
    correctIndex: 1,
    explanation:
      "多重共線性は説明変数間に強い相関がある状態で、重回帰分析で回帰係数が不安定になる問題を引き起こします。VIF（分散拡大要因）で検出できます。",
  },
  {
    id: "math-018",
    category: "データサイエンス力",
    question: "t検定を使う場面として最も適切なものはどれか？",
    choices: [
      "3群以上の平均値を比較する場合",
      "2群の母平均の差を検定する場合",
      "分散の比を検定する場合",
      "カテゴリカルデータの独立性を検定する場合",
    ],
    correctIndex: 1,
    explanation:
      "t検定は2群の母平均の差を検定する際に使用します。3群以上の場合は分散分析（ANOVA）を使用します。t検定にはStudent's t検定やWelchのt検定があります。",
  },
  {
    id: "math-019",
    category: "データサイエンス力",
    question: "対数（log）変換をデータに施す主な目的はどれか？",
    choices: [
      "データの値を全て正にするため",
      "右に裾が長い分布を対称に近づけ、分散を安定化させるため",
      "データの平均値を0にするため",
      "外れ値を除去するため",
    ],
    correctIndex: 1,
    explanation:
      "対数変換は右に歪んだ（正の歪度を持つ）分布を対称に近づけ、分散を安定化させる効果があります。売上データや人口データなどに頻繁に適用されます。",
  },
  {
    id: "math-020",
    category: "データサイエンス力",
    question: "条件付き確率 P(A|B) の意味として正しいものはどれか？",
    choices: [
      "AとBが同時に起こる確率",
      "Bが起きたという条件の下でAが起きる確率",
      "AまたはBが起きる確率",
      "AとBが独立である確率",
    ],
    correctIndex: 1,
    explanation:
      "条件付き確率P(A|B)は、事象Bが起きたことが分かっている条件の下で、事象Aが起きる確率です。P(A|B) = P(A∩B) / P(B) で計算されます。",
  },

  // ===== データサイエンス力（機械学習） =====
  {
    id: "ml-001",
    category: "データサイエンス力",
    question: "教師あり学習に分類されるアルゴリズムはどれか？",
    choices: [
      "k-means法",
      "主成分分析（PCA）",
      "ランダムフォレスト",
      "オートエンコーダ",
    ],
    correctIndex: 2,
    explanation:
      "ランダムフォレストは決定木を複数組み合わせた教師あり学習のアンサンブル手法です。k-means、PCA、オートエンコーダは教師なし学習に分類されます。",
  },
  {
    id: "ml-002",
    category: "データサイエンス力",
    question: "過学習（オーバーフィッティング）を防ぐ手法として適切でないものはどれか？",
    choices: [
      "正則化（L1/L2）",
      "ドロップアウト",
      "学習率を大きくする",
      "交差検証（クロスバリデーション）",
    ],
    correctIndex: 2,
    explanation:
      "学習率を大きくすることは過学習対策ではなく、むしろ学習の不安定化を招きます。正則化、ドロップアウト、交差検証、早期打ち切りなどが有効な過学習対策です。",
  },
  {
    id: "ml-003",
    category: "データサイエンス力",
    question: "勾配降下法において、局所最適解に陥りにくくするための手法はどれか？",
    choices: [
      "バッチサイズを大きくする",
      "モメンタム（慣性項）を導入する",
      "学習率を0に近づける",
      "エポック数を減らす",
    ],
    correctIndex: 1,
    explanation:
      "モメンタムは過去の勾配情報を利用して更新方向に慣性を持たせることで、局所最適解から抜け出しやすくなります。SGDの改良版としてAdamなどが広く使われています。",
  },
  {
    id: "ml-004",
    category: "データサイエンス力",
    question: "精度（Precision）の定義として正しいものはどれか？",
    choices: [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "(TP + TN) / (TP + TN + FP + FN)",
      "2 × Precision × Recall / (Precision + Recall)",
    ],
    correctIndex: 1,
    explanation:
      "精度（Precision）= TP / (TP + FP) で、陽性と予測したもののうち実際に陽性である割合です。再現率（Recall）= TP / (TP + FN) と区別しましょう。",
  },
  {
    id: "ml-005",
    category: "データサイエンス力",
    question: "決定木の分割基準として使われるジニ不純度の値が0になるのはどの場合か？",
    choices: [
      "全てのクラスが均等に混在している場合",
      "ノードに含まれるデータが全て同じクラスの場合",
      "データが2つのクラスに半分ずつ分かれている場合",
      "欠損値が存在する場合",
    ],
    correctIndex: 1,
    explanation:
      "ジニ不純度はノード内のクラスの混在度を表します。全てのデータが同一クラスの場合に0（純粋）となり、クラスが均等に混在するほど値が大きくなります。",
  },
  {
    id: "ml-006",
    category: "データサイエンス力",
    question: "k近傍法（k-NN）の説明として正しいものはどれか？",
    choices: [
      "データをk個のクラスタに分割する手法",
      "最も近いk個のデータの多数決で分類する手法",
      "k個の決定木を組み合わせるアンサンブル手法",
      "k次元に次元削減する手法",
    ],
    correctIndex: 1,
    explanation:
      "k近傍法は、予測対象のデータに最も近いk個の訓練データを探し、その多数決（分類）または平均（回帰）で予測を行う手法です。怠惰学習とも呼ばれます。",
  },
  {
    id: "ml-007",
    category: "データサイエンス力",
    question: "バイアス-バリアンストレードオフの説明として正しいものはどれか？",
    choices: [
      "モデルの複雑さを上げるとバイアスもバリアンスも下がる",
      "モデルの複雑さを上げるとバイアスは下がるがバリアンスは上がる",
      "バイアスとバリアンスは常に等しい",
      "バイアスは訓練データ、バリアンスはテストデータのみに関係する",
    ],
    correctIndex: 1,
    explanation:
      "モデルが複雑になるほどバイアス（系統的な誤差）は減りますが、バリアンス（データへの敏感さ）は増加します。この両者のバランスが汎化性能を決定します。",
  },
  {
    id: "ml-008",
    category: "データサイエンス力",
    question: "サポートベクターマシン（SVM）のカーネルトリックの目的はどれか？",
    choices: [
      "計算速度を向上させる",
      "特徴量の数を減らす",
      "非線形の分離境界を実現する",
      "過学習を防止する",
    ],
    correctIndex: 2,
    explanation:
      "カーネルトリックは、データを高次元空間に写像することで、元の空間では線形分離できないデータを分離可能にする手法です。RBFカーネルや多項式カーネルが代表的です。",
  },
  {
    id: "ml-009",
    category: "データサイエンス力",
    question: "交差検証（k-fold Cross Validation）の主な目的はどれか？",
    choices: [
      "訓練データを増やすこと",
      "モデルの汎化性能をより正確に評価すること",
      "特徴量選択を自動化すること",
      "ハイパーパラメータを自動調整すること",
    ],
    correctIndex: 1,
    explanation:
      "k分割交差検証は、データをk個に分割し、各分割をテストデータとして評価を繰り返すことで、モデルの汎化性能をより安定的に評価する方法です。",
  },
  {
    id: "ml-010",
    category: "データサイエンス力",
    question: "ROC曲線のAUCが0.5であることの意味はどれか？",
    choices: [
      "完璧な分類性能",
      "ランダムな予測と同等の性能",
      "全てを陽性と予測している",
      "全てを陰性と予測している",
    ],
    correctIndex: 1,
    explanation:
      "AUC（Area Under the Curve）が0.5はランダム予測と同等、1.0は完璧な分類を意味します。0.5以下の場合、予測ラベルを反転させることで改善できます。",
  },
  {
    id: "ml-011",
    category: "データサイエンス力",
    question: "畳み込みニューラルネットワーク（CNN）が特に得意とするタスクはどれか？",
    choices: [
      "時系列データの予測",
      "画像認識",
      "テーブルデータの分類",
      "グラフ構造データの分析",
    ],
    correctIndex: 1,
    explanation:
      "CNNは畳み込み層とプーリング層により画像の局所的な特徴を階層的に抽出できるため、画像認識タスクで非常に高い性能を発揮します。",
  },
  {
    id: "ml-012",
    category: "データサイエンス力",
    question: "RNN（再帰型ニューラルネットワーク）が主に扱うデータの種類はどれか？",
    choices: [
      "画像データ",
      "系列データ（時系列・テキストなど）",
      "テーブルデータ",
      "グラフデータ",
    ],
    correctIndex: 1,
    explanation:
      "RNNは隠れ状態を持ち過去の情報を保持できるため、時系列データや自然言語などの系列データの処理に適しています。LSTMやGRUはRNNの改良型です。",
  },
  {
    id: "ml-013",
    category: "データサイエンス力",
    question: "L1正則化（Lasso）の特徴として正しいものはどれか？",
    choices: [
      "パラメータを0に近づけるが、正確に0にはならない",
      "一部のパラメータを正確に0にし、特徴量選択の効果がある",
      "全てのパラメータを均等に縮小する",
      "パラメータの符号を反転させる",
    ],
    correctIndex: 1,
    explanation:
      "L1正則化（Lasso）は損失関数にパラメータの絶対値の和を加えます。これにより一部のパラメータが正確に0になり、自動的な特徴量選択の効果があります。L2正則化（Ridge）は0に近づけますが正確に0にはしません。",
  },
  {
    id: "ml-014",
    category: "データサイエンス力",
    question: "勾配消失問題の説明として正しいものはどれか？",
    choices: [
      "学習率が大きすぎてパラメータが発散する問題",
      "深い層に伝播する勾配が極端に小さくなり学習が進まなくなる問題",
      "訓練データが不足して汎化できない問題",
      "特徴量の数が多すぎて計算が遅くなる問題",
    ],
    correctIndex: 1,
    explanation:
      "勾配消失問題は、深層ニューラルネットワークで誤差逆伝播時に勾配が層を遡るたびに小さくなり、浅い層のパラメータがほとんど更新されなくなる問題です。ReLUやBatch Normalizationが対策として使われます。",
  },
  {
    id: "ml-015",
    category: "データサイエンス力",
    question: "転移学習の説明として正しいものはどれか？",
    choices: [
      "複数のモデルの出力を統合する手法",
      "あるタスクで学習した知識を別のタスクに活用する手法",
      "学習済みモデルを圧縮して軽量化する手法",
      "教師なし学習から教師あり学習に切り替える手法",
    ],
    correctIndex: 1,
    explanation:
      "転移学習は、大規模データで事前学習したモデルの知識を、データが少ない別のタスクに転用する手法です。特に画像認識や自然言語処理で有効です。",
  },
  {
    id: "ml-016",
    category: "データサイエンス力",
    question: "アンサンブル学習の「バギング」の説明として正しいものはどれか？",
    choices: [
      "複数のモデルを直列に並べ、前のモデルの誤差を次のモデルが修正する",
      "訓練データからブートストラップサンプルを作り、複数のモデルの結果を集約する",
      "最も性能の高いモデルだけを選択する方法",
      "異なるアルゴリズムのモデルを重み付き多数決で統合する方法",
    ],
    correctIndex: 1,
    explanation:
      "バギング（Bootstrap Aggregating）はブートストラップ法でデータの復元抽出を行い、複数のモデルを学習させて多数決や平均で予測します。ランダムフォレストはバギングの代表的手法です。",
  },
  {
    id: "ml-017",
    category: "データサイエンス力",
    question: "勾配ブースティング（Gradient Boosting）の説明として正しいものはどれか？",
    choices: [
      "ランダムに選んだモデルの平均を取る手法",
      "前のモデルの残差（誤差）を次のモデルが学習する逐次的な手法",
      "同じモデルを異なるデータで並列に学習させる手法",
      "モデルの出力に勾配降下法を適用する手法",
    ],
    correctIndex: 1,
    explanation:
      "勾配ブースティングは、前のモデルの残差（予測誤差）を次のモデルが学習する逐次的なアンサンブル手法です。XGBoost、LightGBM、CatBoostが代表的な実装です。",
  },
  {
    id: "ml-018",
    category: "データサイエンス力",
    question: "主成分分析（PCA）の目的として最も適切なものはどれか？",
    choices: [
      "クラスタリングを行う",
      "データの次元を削減しながら情報をできるだけ保持する",
      "欠損値を補完する",
      "外れ値を検出する",
    ],
    correctIndex: 1,
    explanation:
      "PCAはデータの分散が最大となる方向（主成分）を見つけ、少ない次元でデータの情報をできるだけ保持した低次元表現を得る手法です。",
  },
  {
    id: "ml-019",
    category: "データサイエンス力",
    question: "強化学習の基本的な枠組みに含まれないものはどれか？",
    choices: [
      "エージェント",
      "環境",
      "教師データ",
      "報酬",
    ],
    correctIndex: 2,
    explanation:
      "強化学習はエージェントが環境と相互作用し、行動に対する報酬を最大化するように学習します。教師あり学習のような正解ラベル（教師データ）は使用しません。",
  },
  {
    id: "ml-020",
    category: "データサイエンス力",
    question: "Transformerモデルの中核をなすメカニズムはどれか？",
    choices: [
      "畳み込み",
      "再帰処理",
      "自己注意（Self-Attention）",
      "プーリング",
    ],
    correctIndex: 2,
    explanation:
      "Transformerは自己注意（Self-Attention）機構により、系列中の各要素が他の全要素との関係を並列に計算できます。BERTやGPTなど多くの大規模言語モデルの基盤アーキテクチャです。",
  },

  // ===== データエンジニアリング力 =====
  {
    id: "de-001",
    category: "データエンジニアリング力",
    question: "SQLにおいて、NULLを含む列の集計でCOUNT(column)とCOUNT(*)の違いはどれか？",
    choices: [
      "違いはない",
      "COUNT(column)はNULLを除外し、COUNT(*)は全行を数える",
      "COUNT(*)はNULLを除外し、COUNT(column)は全行を数える",
      "どちらもNULLを除外する",
    ],
    correctIndex: 1,
    explanation:
      "COUNT(column)は指定列がNULLでない行のみをカウントします。COUNT(*)はNULLの有無に関わらず全行をカウントします。",
  },
  {
    id: "de-002",
    category: "データエンジニアリング力",
    question: "データレイクとデータウェアハウスの違いとして最も適切なものはどれか？",
    choices: [
      "データレイクは構造化データのみ、データウェアハウスは非構造化データのみ扱う",
      "データレイクは非構造化・半構造化データも格納でき、データウェアハウスは構造化データを格納する",
      "データレイクは小規模データ向け、データウェアハウスは大規模データ向け",
      "両者に本質的な違いはない",
    ],
    correctIndex: 1,
    explanation:
      "データレイクは構造化・非構造化・半構造化データをそのまま格納できます。データウェアハウスは分析用に整理された構造化データを格納し、SQLで分析しやすい形になっています。",
  },
  {
    id: "de-003",
    category: "データエンジニアリング力",
    question: "ETLの正しい展開はどれか？",
    choices: [
      "Extract, Transfer, Load",
      "Extract, Transform, Load",
      "Evaluate, Transform, Learn",
      "Export, Transform, Load",
    ],
    correctIndex: 1,
    explanation:
      "ETLはExtract（抽出）、Transform（変換）、Load（読み込み）の略です。データソースからデータを抽出し、必要な変換を行い、目的のデータストアに格納するプロセスです。",
  },
  {
    id: "de-004",
    category: "データエンジニアリング力",
    question: "正規化（データベース設計）の第3正規形の条件として正しいものはどれか？",
    choices: [
      "繰り返し項目がないこと",
      "部分関数従属がないこと",
      "推移的関数従属がないこと",
      "多値従属がないこと",
    ],
    correctIndex: 2,
    explanation:
      "第3正規形は第2正規形を満たし、かつ推移的関数従属がない状態です。第1正規形は繰り返し項目の排除、第2正規形は部分関数従属の排除を条件とします。",
  },
  {
    id: "de-005",
    category: "データエンジニアリング力",
    question: "Apache Sparkの特徴として最も適切なものはどれか？",
    choices: [
      "ディスクベースの処理のみ対応",
      "インメモリ処理により大規模データの高速処理が可能",
      "リレーショナルデータベース管理システム",
      "小規模データ専用の分析ツール",
    ],
    correctIndex: 1,
    explanation:
      "Apache Sparkはインメモリでの分散処理フレームワークです。Hadoop MapReduceと比較して、メモリ上でデータを保持することで反復処理が高速化されます。",
  },
  {
    id: "de-006",
    category: "データエンジニアリング力",
    question: "REST APIのHTTPメソッドで、リソースの新規作成に一般的に使われるものはどれか？",
    choices: ["GET", "POST", "PUT", "DELETE"],
    correctIndex: 1,
    explanation:
      "POSTはリソースの新規作成、GETはリソースの取得、PUTはリソースの更新（置換）、DELETEはリソースの削除に使用されるのが一般的です。",
  },
  {
    id: "de-007",
    category: "データエンジニアリング力",
    question: "SQLのJOINで、両方のテーブルに一致する行のみを返すのはどれか？",
    choices: ["LEFT JOIN", "RIGHT JOIN", "INNER JOIN", "FULL OUTER JOIN"],
    correctIndex: 2,
    explanation:
      "INNER JOINは結合条件に一致する行のみを返します。LEFT JOINは左テーブルの全行、RIGHT JOINは右テーブルの全行、FULL OUTER JOINは両テーブルの全行を返します。",
  },
  {
    id: "de-008",
    category: "データエンジニアリング力",
    question: "NoSQLデータベースの種類として正しくないものはどれか？",
    choices: [
      "キーバリュー型（Redis）",
      "ドキュメント型（MongoDB）",
      "リレーショナル型（PostgreSQL）",
      "グラフ型（Neo4j）",
    ],
    correctIndex: 2,
    explanation:
      "PostgreSQLはリレーショナルデータベース（RDBMS）であり、NoSQLには分類されません。NoSQLにはキーバリュー型、ドキュメント型、カラム型、グラフ型などがあります。",
  },
  {
    id: "de-009",
    category: "データエンジニアリング力",
    question: "データクレンジングの作業として適切でないものはどれか？",
    choices: [
      "重複データの除去",
      "欠損値の補完",
      "外れ値の確認と対処",
      "データ量を増やすために値を自動生成する",
    ],
    correctIndex: 3,
    explanation:
      "データクレンジングは既存データの品質を向上させる作業です。重複除去、欠損値補完、外れ値対処、表記ゆれの統一などが含まれますが、架空のデータを生成することは含まれません。",
  },
  {
    id: "de-010",
    category: "データエンジニアリング力",
    question: "ACID特性のうち「I（Isolation）」が意味するものはどれか？",
    choices: [
      "トランザクションは全て実行されるか全て取り消される",
      "トランザクション完了後のデータは永続化される",
      "複数のトランザクションが互いに干渉しない",
      "トランザクション前後でデータの整合性が保たれる",
    ],
    correctIndex: 2,
    explanation:
      "Isolation（分離性）は、複数のトランザクションが同時に実行されても、互いに影響を及ぼさないことを保証します。A=原子性、C=一貫性、D=耐久性です。",
  },
  {
    id: "de-011",
    category: "データエンジニアリング力",
    question: "SQLのウィンドウ関数 ROW_NUMBER() の説明として正しいものはどれか？",
    choices: [
      "各行にランダムな番号を振る",
      "パーティション内の各行に連番を振る",
      "テーブル全体の行数を返す",
      "重複行を削除する",
    ],
    correctIndex: 1,
    explanation:
      "ROW_NUMBER()はOVER句で指定したパーティション・順序に基づいて、各行に一意の連番を振るウィンドウ関数です。ランキングや重複除去に活用されます。",
  },
  {
    id: "de-012",
    category: "データエンジニアリング力",
    question: "Dockerの主な利点として最も適切なものはどれか？",
    choices: [
      "ハードウェアの性能を直接向上させる",
      "アプリケーションとその依存関係をコンテナとして隔離・再現できる",
      "プログラミング言語を統一できる",
      "データベースのバックアップを自動化する",
    ],
    correctIndex: 1,
    explanation:
      "Dockerはアプリケーションと依存するライブラリ・設定をコンテナとしてパッケージ化し、どの環境でも同一の動作を再現できます。開発・本番環境の差異を解消できます。",
  },
  {
    id: "de-013",
    category: "データエンジニアリング力",
    question: "データパイプラインのオーケストレーションツールとして広く使われているものはどれか？",
    choices: [
      "Jupyter Notebook",
      "Apache Airflow",
      "Tableau",
      "Microsoft Excel",
    ],
    correctIndex: 1,
    explanation:
      "Apache Airflowはデータパイプラインのワークフローをプログラムで定義し、スケジュール実行・監視するオーケストレーションツールです。DAG（有向非巡回グラフ）でタスクの依存関係を管理します。",
  },
  {
    id: "de-014",
    category: "データエンジニアリング力",
    question: "SQLのGROUP BYに関する説明として正しいものはどれか？",
    choices: [
      "GROUP BYで指定した列はSELECT句で使用できない",
      "GROUP BYは集約関数と組み合わせてグループごとの集計を行う",
      "GROUP BYはWHERE句の前に記述する",
      "GROUP BYは1つの列のみ指定できる",
    ],
    correctIndex: 1,
    explanation:
      "GROUP BYは指定した列の値が同じ行をグループ化し、SUM、COUNT、AVGなどの集約関数でグループごとの集計値を算出します。複数列の指定も可能です。",
  },
  {
    id: "de-015",
    category: "データエンジニアリング力",
    question: "CAP定理の説明として正しいものはどれか？",
    choices: [
      "分散システムは一貫性・可用性・分断耐性の3つを同時に完全に満たすことはできない",
      "データベースはCPUとメモリとストレージの3要素で性能が決まる",
      "ネットワークの帯域は常に3つのノード間で均等に分配される",
      "キャッシュ・アプリケーション・永続化の3層構造が最適である",
    ],
    correctIndex: 0,
    explanation:
      "CAP定理は分散システムにおいて、Consistency（一貫性）、Availability（可用性）、Partition Tolerance（分断耐性）の3つを同時に完全に保証することは不可能であるという定理です。",
  },
  {
    id: "de-016",
    category: "データエンジニアリング力",
    question: "Parquet形式の特徴として正しいものはどれか？",
    choices: [
      "行指向のデータ形式でトランザクション処理に適する",
      "列指向のデータ形式で分析クエリに適する",
      "テキストベースの形式で人間が読みやすい",
      "リアルタイムストリーミング専用の形式",
    ],
    correctIndex: 1,
    explanation:
      "Apache Parquetは列指向（カラムナ）のデータ形式で、特定の列のみを読み込む分析クエリで高い性能を発揮します。高い圧縮率と効率的なエンコーディングも特徴です。",
  },
  {
    id: "de-017",
    category: "データエンジニアリング力",
    question: "Git のブランチ戦略で「main（master）ブランチに直接コミットしない」理由として最も適切なものはどれか？",
    choices: [
      "mainブランチではファイルを変更できないため",
      "コードレビューやテストを経てから統合し、品質を保つため",
      "mainブランチはバックアップ専用だから",
      "複数人の同時編集を防ぐため",
    ],
    correctIndex: 1,
    explanation:
      "mainブランチに直接コミットせず、フィーチャーブランチからプルリクエスト経由で統合することで、コードレビューやCI/CDによる品質チェックを確実に行えます。",
  },
  {
    id: "de-018",
    category: "データエンジニアリング力",
    question: "Apache Kafkaの主な用途はどれか？",
    choices: [
      "リレーショナルデータベースの管理",
      "大規模なリアルタイムデータストリーミング",
      "静的Webサイトのホスティング",
      "機械学習モデルの学習",
    ],
    correctIndex: 1,
    explanation:
      "Apache Kafkaは分散メッセージストリーミングプラットフォームで、大量のリアルタイムデータ（ログ、イベント、トランザクション）を高スループットで処理します。",
  },
  {
    id: "de-019",
    category: "データエンジニアリング力",
    question: "SQLインジェクションの対策として最も有効なものはどれか？",
    choices: [
      "入力値の文字数を制限する",
      "プリペアドステートメント（パラメータ化クエリ）を使用する",
      "HTTPSで通信を暗号化する",
      "データベースのパスワードを定期変更する",
    ],
    correctIndex: 1,
    explanation:
      "プリペアドステートメントはSQL文とパラメータを分離するため、ユーザー入力がSQL文の一部として解釈されることを防ぎ、SQLインジェクションを根本的に防止します。",
  },
  {
    id: "de-020",
    category: "データエンジニアリング力",
    question: "データメッシュの考え方として正しいものはどれか？",
    choices: [
      "全てのデータを1つの中央データベースに集約する",
      "各ドメインチームがデータの所有権と提供責任を持つ分散型アプローチ",
      "データをメッシュ状のネットワークトポロジーで転送する",
      "NoSQLデータベースのみを使用するアーキテクチャ",
    ],
    correctIndex: 1,
    explanation:
      "データメッシュは、データの所有権を各ドメインチームに分散させ、データを「プロダクト」として扱う分散型データアーキテクチャの考え方です。中央集権的なデータチームへの依存を減らします。",
  },

  // ===== ビジネス力 =====
  {
    id: "biz-001",
    category: "ビジネス力",
    question: "KPIの説明として最も適切なものはどれか？",
    choices: [
      "企業の最終的な目標値",
      "目標達成に向けた進捗を測る中間指標",
      "プロジェクトの予算管理指標",
      "従業員の人事評価指標",
    ],
    correctIndex: 1,
    explanation:
      "KPI（Key Performance Indicator：重要業績評価指標）は、最終目標（KGI）の達成に向けた過程を数値化した中間指標です。進捗管理や改善活動に活用されます。",
  },
  {
    id: "biz-002",
    category: "ビジネス力",
    question: "CRISP-DMにおけるデータ分析プロジェクトの最初のフェーズはどれか？",
    choices: [
      "データ理解",
      "ビジネス理解",
      "データ準備",
      "モデリング",
    ],
    correctIndex: 1,
    explanation:
      "CRISP-DM（Cross-Industry Standard Process for Data Mining）の6つのフェーズは、①ビジネス理解→②データ理解→③データ準備→④モデリング→⑤評価→⑥展開の順です。",
  },
  {
    id: "biz-003",
    category: "ビジネス力",
    question: "A/Bテストの説明として最も適切なものはどれか？",
    choices: [
      "2つの異なるシステムの性能を比較するテスト",
      "2つの異なるバージョンをランダムに割り当てて効果を比較する実験手法",
      "テスト工程のAフェーズとBフェーズの総称",
      "アルファテストとベータテストの略称",
    ],
    correctIndex: 1,
    explanation:
      "A/Bテストは、2つの異なるバージョン（A：コントロール群、B：テスト群）をユーザーにランダムに割り当て、どちらがより効果的かを統計的に検証する実験手法です。",
  },
  {
    id: "biz-004",
    category: "ビジネス力",
    question: "個人情報保護法における「要配慮個人情報」に該当しないものはどれか？",
    choices: [
      "人種",
      "病歴",
      "メールアドレス",
      "犯罪の経歴",
    ],
    correctIndex: 2,
    explanation:
      "要配慮個人情報には、人種、信条、病歴、犯罪歴、障害などが含まれます。メールアドレスは個人情報ですが、要配慮個人情報には該当しません。",
  },
  {
    id: "biz-005",
    category: "ビジネス力",
    question: "データドリブン経営の説明として最も適切なものはどれか？",
    choices: [
      "データベースを中心としたシステム設計手法",
      "経験と勘に基づいて迅速に意思決定する経営手法",
      "データの収集・分析結果に基づいて意思決定を行う経営手法",
      "全てのビジネスプロセスを自動化する手法",
    ],
    correctIndex: 2,
    explanation:
      "データドリブン経営は、経験や勘だけでなく、客観的なデータに基づいて意思決定を行う経営手法です。BI（ビジネスインテリジェンス）ツールなどが活用されます。",
  },
  {
    id: "biz-006",
    category: "ビジネス力",
    question: "GDPRの説明として正しいものはどれか？",
    choices: [
      "日本の個人情報保護法の別称",
      "EUにおける一般データ保護規則",
      "米国のデータセキュリティ基準",
      "国際的なデータ通信プロトコル",
    ],
    correctIndex: 1,
    explanation:
      "GDPR（General Data Protection Regulation）はEUの一般データ保護規則で、2018年に施行されました。EU域内の個人データの処理と移転に関する厳格なルールを定めています。",
  },
  {
    id: "biz-007",
    category: "ビジネス力",
    question: "RFM分析の「R」が表すものはどれか？",
    choices: [
      "Revenue（収益）",
      "Recency（最終購買日からの経過日数）",
      "Retention（顧客維持率）",
      "Reach（到達率）",
    ],
    correctIndex: 1,
    explanation:
      "RFM分析はRecency（最終購買日）、Frequency（購買頻度）、Monetary（購買金額）の3つの指標で顧客をセグメント化する手法です。",
  },
  {
    id: "biz-008",
    category: "ビジネス力",
    question: "データサイエンティストに求められるスキルセットとして、DS検定で定義されている3つの力はどれか？",
    choices: [
      "プログラミング力・分析力・報告力",
      "データサイエンス力・データエンジニアリング力・ビジネス力",
      "統計力・AI力・コミュニケーション力",
      "数学力・プログラミング力・ドメイン知識力",
    ],
    correctIndex: 1,
    explanation:
      "DS検定ではデータサイエンティストに必要なスキルとして「データサイエンス力」「データエンジニアリング力」「ビジネス力」の3つを定義しています。",
  },
  {
    id: "biz-009",
    category: "ビジネス力",
    question: "AIの倫理的問題として「公平性」が問題になるケースはどれか？",
    choices: [
      "AIモデルの計算コストが高い",
      "学習データの偏りにより特定の属性に不利な判断をする",
      "AIの処理速度が遅い",
      "データの保存容量が不足する",
    ],
    correctIndex: 1,
    explanation:
      "AI倫理における公平性の問題は、学習データに含まれるバイアスにより、特定の人種・性別・年齢層などに不公平な判断や差別的な結果をもたらすケースを指します。",
  },
  {
    id: "biz-010",
    category: "ビジネス力",
    question: "データ分析プロジェクトにおいて、最初に明確にすべきものはどれか？",
    choices: [
      "使用するツールと技術",
      "ビジネス上の課題と目的",
      "データの収集方法",
      "分析モデルの種類",
    ],
    correctIndex: 1,
    explanation:
      "データ分析プロジェクトではまずビジネス課題と目的を明確にすることが最重要です。目的が不明確なまま分析を始めると、的外れな結果となるリスクがあります。",
  },
  {
    id: "biz-011",
    category: "ビジネス力",
    question: "コホート分析の説明として正しいものはどれか？",
    choices: [
      "製品の原価と利益率を分析する手法",
      "同じ時期・条件のグループ（コホート）ごとに行動を追跡・比較する手法",
      "組織の階層構造を分析する手法",
      "競合他社の市場シェアを分析する手法",
    ],
    correctIndex: 1,
    explanation:
      "コホート分析は、同じ時期に登録・購入などを行ったユーザー群をグループ化し、時間経過に伴う行動変化（継続率、LTVなど）を追跡・比較する手法です。",
  },
  {
    id: "biz-012",
    category: "ビジネス力",
    question: "PoC（Proof of Concept）の目的として最も適切なものはどれか？",
    choices: [
      "最終製品を完成させること",
      "アイデアやコンセプトの実現可能性を検証すること",
      "大量のユーザーに向けてサービスを提供すること",
      "プロジェクトの予算を確定させること",
    ],
    correctIndex: 1,
    explanation:
      "PoCは新しい概念やアイデアが技術的・ビジネス的に実現可能かを、小規模な試作やプロトタイプで検証するプロセスです。本格開発前のリスク軽減に役立ちます。",
  },
  {
    id: "biz-013",
    category: "ビジネス力",
    question: "LTV（顧客生涯価値）の説明として正しいものはどれか？",
    choices: [
      "顧客1人あたりの初回購入金額",
      "顧客が取引期間全体を通じて企業にもたらす総利益の予測値",
      "顧客の満足度を数値化した指標",
      "新規顧客の獲得コスト",
    ],
    correctIndex: 1,
    explanation:
      "LTV（Life Time Value）は顧客が企業との取引期間全体で生み出す利益の合計です。LTV > CAC（顧客獲得コスト）であることがビジネスの持続性に重要です。",
  },
  {
    id: "biz-014",
    category: "ビジネス力",
    question: "アジャイル開発の特徴として最も適切なものはどれか？",
    choices: [
      "プロジェクト開始前に全ての要件を確定させる",
      "短いサイクルで開発・テスト・フィードバックを繰り返す反復的な開発手法",
      "開発フェーズとテストフェーズを明確に分離する",
      "1人の開発者が全工程を担当する",
    ],
    correctIndex: 1,
    explanation:
      "アジャイル開発はスプリントと呼ばれる短い開発サイクル（1-4週間）を繰り返し、変化する要件に柔軟に対応する手法です。スクラムやカンバンが代表的なフレームワークです。",
  },
  {
    id: "biz-015",
    category: "ビジネス力",
    question: "データの「匿名化」と「仮名化」の違いとして正しいものはどれか？",
    choices: [
      "匿名化と仮名化は同じ意味である",
      "匿名化は元のデータに復元不可能、仮名化は追加情報があれば復元可能",
      "仮名化は元のデータに復元不可能、匿名化は追加情報があれば復元可能",
      "匿名化はデータの暗号化、仮名化はデータの圧縮を指す",
    ],
    correctIndex: 1,
    explanation:
      "匿名化は個人の特定が不可逆的にできなくなる処理です。仮名化は直接的な識別情報を仮名に置き換えますが、対応表などの追加情報があれば元に戻せます。GDPRでは仮名化データも個人データとして扱われます。",
  },
  {
    id: "biz-016",
    category: "ビジネス力",
    question: "バスケット分析（アソシエーション分析）で用いられる指標「支持度（Support）」の意味はどれか？",
    choices: [
      "商品Aを買った人が商品Bも買う確率",
      "商品Aと商品Bが同時に購入されるトランザクションの割合",
      "商品Aの売上に対する商品Bの売上の比率",
      "顧客が商品を推薦する確率",
    ],
    correctIndex: 1,
    explanation:
      "支持度（Support）は全トランザクションのうち、対象の商品組み合わせが同時に含まれるトランザクションの割合です。確信度（Confidence）はAを買った人がBも買う条件付き確率です。",
  },
  {
    id: "biz-017",
    category: "ビジネス力",
    question: "NPS（Net Promoter Score）の説明として正しいものはどれか？",
    choices: [
      "企業の純利益を売上で割った指標",
      "顧客が他者に推薦する度合いを測る顧客ロイヤルティ指標",
      "ネットワークの性能を測定する指標",
      "新規顧客獲得数から離脱数を引いた指標",
    ],
    correctIndex: 1,
    explanation:
      "NPSは「この製品・サービスを友人に薦める可能性は？」という質問への0-10の回答から算出します。推奨者（9-10）の割合から批判者（0-6）の割合を引いた値です。",
  },
  {
    id: "biz-018",
    category: "ビジネス力",
    question: "データガバナンスの説明として最も適切なものはどれか？",
    choices: [
      "データの分析手法を統一すること",
      "データの品質・セキュリティ・利活用に関する組織的な管理体制と方針",
      "データベースのバックアップ運用",
      "データサイエンティストの育成方針",
    ],
    correctIndex: 1,
    explanation:
      "データガバナンスは、組織全体でデータの品質管理、アクセス権限、セキュリティ、コンプライアンスなどを体系的に管理するための方針・プロセス・組織体制です。",
  },
  {
    id: "biz-019",
    category: "ビジネス力",
    question: "因果推論において、相関関係と因果関係の違いの説明として正しいものはどれか？",
    choices: [
      "相関関係があれば必ず因果関係がある",
      "因果関係があれば必ず相関関係がある",
      "相関関係は2変数の共変動を示すが、必ずしも原因と結果の関係を意味しない",
      "因果関係と相関関係は同じ概念の別名称である",
    ],
    correctIndex: 2,
    explanation:
      "相関関係は2つの変数が一緒に変動することを示しますが、第三の変数（交絡因子）による見かけの関係の可能性があり、因果関係を直接意味しません。「相関は因果ではない」は重要な原則です。",
  },
  {
    id: "biz-020",
    category: "ビジネス力",
    question: "ダッシュボードを設計する際に最も重要な原則はどれか？",
    choices: [
      "できるだけ多くのグラフを1画面に表示する",
      "閲覧者のニーズに合わせ、重要な情報を一目で把握できるようにする",
      "全てのデータを網羅的に表示する",
      "最新の技術を使って3Dグラフを多用する",
    ],
    correctIndex: 1,
    explanation:
      "ダッシュボードは意思決定者が重要な指標を一目で把握できることが最も重要です。情報過多は避け、ターゲットユーザーの目的に合わせた情報設計が求められます。",
  },
];
