import type { Question } from "../types";

export const newDeBizQuestions: Question[] = [
  // ===== データエンジニアリング（追加分） =====
  {
    id: "de-021",
    category: "データエンジニアリング力",
    question:
      "SQLにおいて、サブクエリの結果に名前を付けて再利用できるCTE（共通テーブル式）を定義するために使用するキーワードはどれか？",
    choices: ["TEMP", "WITH", "AS SELECT", "DEFINE"],
    correctIndex: 1,
    explanation:
      "CTE（Common Table Expression）はWITH句を使って定義します。WITH cte_name AS (SELECT ...) のように記述し、複雑なサブクエリに名前を付けて可読性を高めたり、同じクエリ内で複数回参照したりできます。再帰CTEを使えば階層構造データの探索も可能です。",
  },
  {
    id: "de-022",
    category: "データエンジニアリング力",
    question:
      "SQLのHAVING句の説明として最も適切なものはどれか？",
    choices: [
      "テーブル結合の条件を指定する",
      "GROUP BYで集約した結果に対して条件を指定する",
      "WHERE句の代替として使用する",
      "SELECT句で取得するカラムを制限する",
    ],
    correctIndex: 1,
    explanation:
      "HAVING句はGROUP BYで集約した後の結果に対して条件を絞り込むために使用します。WHERE句が個々の行に対するフィルタリングであるのに対し、HAVINGはSUMやCOUNTなどの集約関数の結果に対して条件を適用できる点が異なります。",
  },
  {
    id: "de-023",
    category: "データエンジニアリング力",
    question:
      "SQLのUNIONとUNION ALLの違いについて正しい説明はどれか？",
    choices: [
      "UNIONは2つのテーブルを結合し、UNION ALLは3つ以上のテーブルを結合する",
      "UNIONは重複行を除去し、UNION ALLは重複行を含めてすべての行を返す",
      "UNIONは数値型のみ対応し、UNION ALLはすべてのデータ型に対応する",
      "UNIONは内部結合、UNION ALLは外部結合を意味する",
    ],
    correctIndex: 1,
    explanation:
      "UNIONは2つのSELECT結果を結合する際に重複行を自動的に除去しますが、UNION ALLは重複行もそのまま含めて返します。UNION ALLは重複チェックの処理が不要なため、一般的にUNIONよりもパフォーマンスが良いです。",
  },
  {
    id: "de-024",
    category: "データエンジニアリング力",
    question:
      "リレーショナルデータベースで一般的に使用されるB-treeインデックスの特徴として最も適切なものはどれか？",
    choices: [
      "ハッシュ関数を用いて完全一致検索のみを高速化する",
      "データを平衡木構造で保持し、範囲検索やソートを効率的に行える",
      "全文検索に特化したインデックス構造である",
      "メモリ上にのみ存在し、ディスクには書き込まれない",
    ],
    correctIndex: 1,
    explanation:
      "B-treeインデックスはデータを平衡木構造で管理し、等値検索だけでなく範囲検索（WHERE price BETWEEN 100 AND 200）やORDER BYのソートも効率化できます。RDBMSのデフォルトのインデックスタイプとして広く採用されており、O(log n)の計算量でデータにアクセスできます。",
  },
  {
    id: "de-025",
    category: "データエンジニアリング力",
    question:
      "データベースのパーティショニングにおいて、特定のカラムの値の範囲に基づいてデータを分割する方式は何と呼ばれるか？",
    choices: [
      "ハッシュパーティショニング",
      "リストパーティショニング",
      "レンジパーティショニング",
      "ラウンドロビンパーティショニング",
    ],
    correctIndex: 2,
    explanation:
      "レンジパーティショニングは、日付や数値などのカラムの値の範囲に基づいてデータを分割する方式です。例えば、売上データを月別に分割することで、特定の期間のクエリが対象パーティションのみをスキャンすればよく、大幅なパフォーマンス向上が期待できます。",
  },
  {
    id: "de-026",
    category: "データエンジニアリング力",
    question:
      "データベースのレプリケーションにおいて、1つのマスターノードが書き込みを受け付け、複数のスレーブノードに非同期でデータをコピーする方式は何と呼ばれるか？",
    choices: [
      "マルチマスターレプリケーション",
      "同期レプリケーション",
      "非同期マスター・スレーブレプリケーション",
      "双方向レプリケーション",
    ],
    correctIndex: 2,
    explanation:
      "非同期マスター・スレーブレプリケーションでは、マスターが書き込みを処理し、その変更を非同期でスレーブに伝播します。読み取りをスレーブに分散させることでスケーラビリティを向上できますが、マスターとスレーブ間で一時的なデータの不整合（レプリケーションラグ）が発生する可能性があります。",
  },
  {
    id: "de-027",
    category: "データエンジニアリング力",
    question:
      "MapReduceプログラミングモデルにおけるReduce処理の役割として最も適切なものはどれか？",
    choices: [
      "入力データを分割して各ノードに配布する",
      "Map処理の出力をキーごとに集約・統合する",
      "処理結果をディスクに書き込む",
      "入力データのフォーマットを変換する",
    ],
    correctIndex: 1,
    explanation:
      "MapReduceモデルでは、Map処理がデータをキー・バリューペアに変換し、Reduce処理が同じキーを持つ値を集約・統合します。例えば単語カウントでは、Mapが各単語に1を割り当て、Reduceが同じ単語の出現回数を合計します。この分散処理パラダイムにより大規模データの並列処理が可能になります。",
  },
  {
    id: "de-028",
    category: "データエンジニアリング力",
    question:
      "Hadoopの分散ファイルシステムであるHDFSの特徴として最も適切なものはどれか？",
    choices: [
      "小さなファイルの高速なランダムアクセスに最適化されている",
      "データブロックを複数ノードにレプリケーションして高い耐障害性を実現する",
      "リアルタイムの低レイテンシ処理に特化している",
      "データは暗号化された状態でのみ保存される",
    ],
    correctIndex: 1,
    explanation:
      "HDFSはデータを大きなブロック（デフォルト128MB）に分割し、各ブロックを通常3つのノードにレプリケーションすることで、ノード障害時にもデータを失わない高い耐障害性を実現します。大容量のバッチ処理に適しており、コモディティハードウェア上で動作するよう設計されています。",
  },
  {
    id: "de-029",
    category: "データエンジニアリング力",
    question:
      "クラウド上のフルマネージド型データウェアハウスサービスとして、SQLクエリでペタバイト規模のデータ分析が可能なGoogle Cloudのサービスはどれか？",
    choices: ["Amazon S3", "Google BigQuery", "Azure Blob Storage", "Amazon Redshift"],
    correctIndex: 1,
    explanation:
      "Google BigQueryはサーバーレスのフルマネージド型データウェアハウスで、標準SQLを使ってペタバイト規模のデータを高速に分析できます。Amazon S3とAzure Blob Storageはオブジェクトストレージサービスであり、Amazon RedshiftはAWSのDWHサービスです。BigQueryはカラムナーストレージと分散処理により高いクエリ性能を実現しています。",
  },
  {
    id: "de-030",
    category: "データエンジニアリング力",
    question:
      "Kubernetesの説明として最も適切なものはどれか？",
    choices: [
      "仮想マシンを作成・管理するためのハイパーバイザー",
      "コンテナ化されたアプリケーションの自動デプロイ、スケーリング、運用管理を行うオーケストレーションツール",
      "サーバーレス関数の実行環境を提供するサービス",
      "コンテナイメージをビルドするためのツール",
    ],
    correctIndex: 1,
    explanation:
      "Kubernetesはコンテナオーケストレーションプラットフォームであり、コンテナのデプロイ、スケーリング、負荷分散、ヘルスチェック、自動復旧などを自動的に管理します。Googleが開発し現在はCNCFが管理しているOSSで、クラウドネイティブなアプリケーション運用の事実上の標準となっています。",
  },
  {
    id: "de-031",
    category: "データエンジニアリング力",
    question:
      "CI/CDパイプラインにおけるCI（継続的インテグレーション）の主な目的として最も適切なものはどれか？",
    choices: [
      "本番環境への自動デプロイを行う",
      "コード変更を頻繁にマージし、自動ビルド・テストにより品質を継続的に検証する",
      "インフラストラクチャのプロビジョニングを自動化する",
      "データベースのバックアップを定期的に取得する",
    ],
    correctIndex: 1,
    explanation:
      "CI（Continuous Integration）は、開発者がコード変更を頻繁に共有リポジトリにマージし、その都度自動的にビルドやテストを実行することで、統合の問題を早期に発見する手法です。CD（Continuous Delivery/Deployment）と組み合わせることで、コードの変更からデプロイまでのプロセス全体を自動化できます。",
  },
  {
    id: "de-032",
    category: "データエンジニアリング力",
    question:
      "データ交換フォーマットとしてJSONとXMLを比較した場合、JSONの特徴として最も適切なものはどれか？",
    choices: [
      "スキーマ定義言語（XSD）が標準で用意されている",
      "XMLよりも冗長性が低く、軽量でパースが高速である",
      "名前空間（namespace）の機能を持つ",
      "コメントを記述できる",
    ],
    correctIndex: 1,
    explanation:
      "JSONはXMLと比較して構文がシンプルで冗長性が低く、データサイズが小さくなるためパースも高速です。Web APIのデータ交換フォーマットとして広く採用されています。一方XMLはスキーマ定義（XSD）、名前空間、XSLT変換など高度な機能を持ち、設定ファイルやドキュメント記述に使われることが多いです。",
  },
  {
    id: "de-033",
    category: "データエンジニアリング力",
    question:
      "Schema-on-readとSchema-on-writeの違いについて正しい説明はどれか？",
    choices: [
      "Schema-on-readはデータ書き込み時にスキーマを強制し、Schema-on-writeは読み取り時にスキーマを適用する",
      "Schema-on-readはデータ読み取り時にスキーマを適用し、Schema-on-writeはデータ書き込み時にスキーマを強制する",
      "両者に違いはなく、同じ概念の別名である",
      "Schema-on-readはRDBMS専用、Schema-on-writeはNoSQL専用の概念である",
    ],
    correctIndex: 1,
    explanation:
      "Schema-on-writeはRDBMSのようにデータ書き込み時にスキーマを強制し、データの整合性を保証します。Schema-on-readはデータレイクのように生データをそのまま保存し、読み取り時にスキーマを適用する方式で、柔軟性が高く多様なデータ形式に対応できます。",
  },
  {
    id: "de-034",
    category: "データエンジニアリング力",
    question:
      "データカタログの主な役割として最も適切なものはどれか？",
    choices: [
      "データの物理的なバックアップを管理する",
      "組織内のデータ資産のメタデータを一元管理し、データの検索・発見を容易にする",
      "データのリアルタイム処理を高速化する",
      "データベースのインデックスを自動最適化する",
    ],
    correctIndex: 1,
    explanation:
      "データカタログは、データの所在、スキーマ、所有者、品質、利用状況などのメタデータを一元的に管理するツールです。データの検索・発見を容易にし、データガバナンスを支援します。代表的なツールにはApache Atlas、AWS Glue Data Catalog、Google Data Catalogなどがあります。",
  },
  {
    id: "de-035",
    category: "データエンジニアリング力",
    question:
      "データリネージ（Data Lineage）の説明として最も適切なものはどれか？",
    choices: [
      "データの暗号化方式を記録する仕組み",
      "データがソースから最終的な出力に至るまでの変換・移動の流れを追跡する仕組み",
      "データベースのパフォーマンスを継続的に監視する仕組み",
      "データのバージョンを管理する仕組み",
    ],
    correctIndex: 1,
    explanation:
      "データリネージは、データがどこから来て、どのような変換を経て、どこに格納されたかという一連の流れを追跡・可視化する仕組みです。データの信頼性検証、問題発生時の影響範囲特定、規制対応（コンプライアンス）などに不可欠であり、データガバナンスの重要な構成要素です。",
  },
  {
    id: "de-036",
    category: "データエンジニアリング力",
    question:
      "バッチ処理とストリーム処理を比較した場合、ストリーム処理の特徴として最も適切なものはどれか？",
    choices: [
      "大量のデータをまとめて定期的に処理し、高いスループットを実現する",
      "データが到着するたびにリアルタイムまたはニアリアルタイムで処理を行う",
      "処理結果の正確性がバッチ処理より常に高い",
      "必要な計算資源がバッチ処理より常に少ない",
    ],
    correctIndex: 1,
    explanation:
      "ストリーム処理は、データが発生・到着するたびにリアルタイムまたはニアリアルタイムで処理を行う方式です。不正検知やリアルタイムダッシュボードなど即時性が求められるユースケースに適しています。一方バッチ処理は大量のデータをまとめて処理し、高いスループットと正確性を実現します。",
  },
  {
    id: "de-037",
    category: "データエンジニアリング力",
    question:
      "Lambdaアーキテクチャの構成要素として正しい組み合わせはどれか？",
    choices: [
      "入力層、処理層、出力層",
      "バッチレイヤー、スピードレイヤー、サービングレイヤー",
      "データレイヤー、ロジックレイヤー、プレゼンテーションレイヤー",
      "収集層、蓄積層、可視化層",
    ],
    correctIndex: 1,
    explanation:
      "Lambdaアーキテクチャは、バッチレイヤー（大規模データの正確な処理）、スピードレイヤー（リアルタイムデータの低レイテンシ処理）、サービングレイヤー（両レイヤーの結果を統合して提供）の3層で構成されます。バッチ処理の正確性とストリーム処理の即時性を両立させるアーキテクチャパターンです。",
  },
  {
    id: "de-038",
    category: "データエンジニアリング力",
    question:
      "マイクロサービスアーキテクチャの特徴として最も適切なものはどれか？",
    choices: [
      "単一のデータベースをすべてのサービスで共有する",
      "アプリケーションを小さな独立したサービスに分割し、それぞれが独自のデータストアを持つ",
      "すべての機能を1つのデプロイ単位にまとめる",
      "サービス間の通信は共有メモリを通じて行う",
    ],
    correctIndex: 1,
    explanation:
      "マイクロサービスアーキテクチャは、アプリケーションを小さな独立したサービスに分割し、各サービスが独自のデータストアを持ち、APIを通じて通信する設計パターンです。各サービスを独立してデプロイ・スケーリングでき、異なる技術スタックを使うことも可能です。一方で分散システムの複雑性が増す課題もあります。",
  },
  {
    id: "de-039",
    category: "データエンジニアリング力",
    question:
      "GraphQLの特徴としてRESTと比較した場合、最も適切なものはどれか？",
    choices: [
      "サーバー側が返すデータの構造を固定的に定義する",
      "クライアントが必要なデータの構造と項目を指定してリクエストできる",
      "HTTPプロトコルを使用しない独自の通信方式である",
      "キャッシュの仕組みがRESTより常に優れている",
    ],
    correctIndex: 1,
    explanation:
      "GraphQLはクライアントが必要なデータの構造と項目をクエリで指定できるため、オーバーフェッチ（不要なデータの取得）やアンダーフェッチ（データ不足による追加リクエスト）を防ぐことができます。RESTでは各エンドポイントが返すデータ構造がサーバー側で固定されているのに対し、GraphQLはより柔軟なデータ取得が可能です。",
  },
  {
    id: "de-040",
    category: "データエンジニアリング力",
    question:
      "OAuth 2.0における「アクセストークン」の役割として最も適切なものはどれか？",
    choices: [
      "ユーザーのパスワードを暗号化して保存する",
      "クライアントがリソースサーバーの保護されたリソースにアクセスするための認可情報を表す",
      "ユーザーの本人確認（認証）を行う",
      "通信を暗号化するための鍵として使用する",
    ],
    correctIndex: 1,
    explanation:
      "OAuth 2.0のアクセストークンは、クライアントアプリケーションがリソースサーバー上の保護されたリソースへアクセスするための認可情報です。ユーザーのパスワードをクライアントに渡すことなく、限定されたスコープのアクセス権を委譲できる点が重要です。OAuth 2.0は認可（Authorization）のフレームワークであり、認証（Authentication）自体はOpenID Connectなどで補完されます。",
  },
  {
    id: "de-041",
    category: "データエンジニアリング力",
    question:
      "JWT（JSON Web Token）の構造として正しいものはどれか？",
    choices: [
      "ヘッダー、ペイロード、署名の3つの部分で構成される",
      "ユーザー名とパスワードの2つの部分で構成される",
      "公開鍵と秘密鍵の2つの部分で構成される",
      "トークンID、有効期限、スコープの3つの部分で構成される",
    ],
    correctIndex: 0,
    explanation:
      "JWTはヘッダー（アルゴリズムとトークンタイプ）、ペイロード（クレームと呼ばれるユーザー情報や有効期限などのデータ）、署名（改ざん検知用）の3部分をBase64URLエンコードし、ドット（.）で連結した構造です。ステートレスな認証・認可に広く使用されています。",
  },
  {
    id: "de-042",
    category: "データエンジニアリング力",
    question:
      "データバージョニングツールであるDVC（Data Version Control）の主な目的として最も適切なものはどれか？",
    choices: [
      "データベースのスキーマ変更を管理する",
      "機械学習プロジェクトにおけるデータセットやモデルのバージョンをGitと連携して管理する",
      "リアルタイムデータの品質を監視する",
      "APIのバージョン管理を行う",
    ],
    correctIndex: 1,
    explanation:
      "DVCはGitと連携して大規模なデータファイルや機械学習モデルのバージョン管理を行うオープンソースツールです。Git自体は大容量ファイルの管理に向いていないため、DVCがデータの実体をリモートストレージに保存し、Gitにはメタデータのみを記録することで、実験の再現性とトレーサビリティを確保します。",
  },
  {
    id: "de-043",
    category: "データエンジニアリング力",
    question:
      "Feature Store（特徴量ストア）の主な役割として最も適切なものはどれか？",
    choices: [
      "機械学習モデルのハイパーパラメータを自動最適化する",
      "機械学習で使用する特徴量を一元管理し、学習時と推論時で一貫した特徴量を提供する",
      "学習データのラベリングを自動化する",
      "モデルのデプロイとサービングを管理する",
    ],
    correctIndex: 1,
    explanation:
      "Feature Storeは特徴量の定義、計算、保存、提供を一元管理するシステムです。チーム間での特徴量の再利用を促進し、学習時（バッチ）と推論時（リアルタイム）で同一の特徴量を提供することで、Training-Serving Skewを防ぎます。代表的なツールにFeast、Tecton、Hopsworksなどがあります。",
  },
  {
    id: "de-044",
    category: "データエンジニアリング力",
    question:
      "dbt（data build tool）の説明として最も適切なものはどれか？",
    choices: [
      "データの抽出（Extract）と読み込み（Load）を行うETLツール",
      "SQLベースでデータウェアハウス内のデータ変換（Transform）を管理するツール",
      "リアルタイムストリーム処理フレームワーク",
      "データの可視化・ダッシュボード作成ツール",
    ],
    correctIndex: 1,
    explanation:
      "dbtはELTアプローチにおけるT（Transform）に特化したツールで、SQLのSELECT文でデータ変換ロジックを記述し、バージョン管理、テスト、ドキュメント生成などソフトウェアエンジニアリングのベストプラクティスをデータ変換に適用できます。Analytics Engineeringの中核ツールとして広く採用されています。",
  },
  {
    id: "de-045",
    category: "データエンジニアリング力",
    question:
      "Snowflakeの特徴的なアーキテクチャとして、ストレージとコンピュートを独立してスケーリングできる設計は何と呼ばれるか？",
    choices: [
      "シェアードナッシング・アーキテクチャ",
      "ストレージとコンピュートの分離アーキテクチャ",
      "マスター・スレーブ・アーキテクチャ",
      "ピアツーピア・アーキテクチャ",
    ],
    correctIndex: 1,
    explanation:
      "Snowflakeはストレージとコンピュート（仮想ウェアハウス）を独立したレイヤーとして分離するアーキテクチャを採用しています。これにより、それぞれを必要に応じて独立にスケーリングでき、コスト効率が高まります。複数のコンピュートクラスタが同一のストレージにアクセスでき、ワークロードの分離も容易です。",
  },
  {
    id: "de-046",
    category: "データエンジニアリング力",
    question:
      "Infrastructure as Code（IaC）ツールであるTerraformの特徴として最も適切なものはどれか？",
    choices: [
      "特定のクラウドプロバイダー専用のツールである",
      "宣言的な設定ファイルでインフラストラクチャを定義し、複数のクラウドプロバイダーに対応する",
      "コンテナイメージのビルドに特化したツールである",
      "アプリケーションコードの自動テストツールである",
    ],
    correctIndex: 1,
    explanation:
      "TerraformはHashiCorpが開発したIaCツールで、HCL（HashiCorp Configuration Language）という宣言的な言語でインフラを定義します。AWS、GCP、Azureなど複数のクラウドプロバイダーに対応しており、インフラの状態管理（state）により、現在のインフラと望ましい状態の差分を検出して適用できます。",
  },
  {
    id: "de-047",
    category: "データエンジニアリング力",
    question:
      "システムの監視とオブザーバビリティにおいて、「オブザーバビリティの3本柱」として一般的に挙げられる組み合わせはどれか？",
    choices: [
      "CPU、メモリ、ディスク",
      "メトリクス、ログ、トレース",
      "可用性、信頼性、保守性",
      "認証、認可、監査",
    ],
    correctIndex: 1,
    explanation:
      "オブザーバビリティの3本柱は、メトリクス（数値データの時系列記録）、ログ（イベントの詳細記録）、トレース（分散システムにおけるリクエストの追跡）です。これらを組み合わせることで、システムの内部状態を外部から観測・理解し、障害の原因特定や性能改善を行うことができます。",
  },
  {
    id: "de-048",
    category: "データエンジニアリング力",
    question:
      "APIのレート制限（Rate Limiting）を実装する主な目的として最も適切なものはどれか？",
    choices: [
      "APIのレスポンスデータを圧縮する",
      "過剰なリクエストからサーバーを保護し、サービスの安定性と公平性を確保する",
      "APIのバージョン管理を行う",
      "リクエストの認証を行う",
    ],
    correctIndex: 1,
    explanation:
      "APIのレート制限は、一定時間内のリクエスト数を制限することで、DoS攻撃や過負荷からサーバーを保護し、すべてのユーザーに対して公平なリソース配分を実現します。一般的な実装方法にはトークンバケット、リーキーバケット、固定ウィンドウ、スライディングウィンドウなどのアルゴリズムがあります。",
  },
  {
    id: "de-049",
    category: "データエンジニアリング力",
    question:
      "SQLのCASE式の説明として最も適切なものはどれか？",
    choices: [
      "テーブルの結合条件を動的に変更する",
      "条件に応じて異なる値を返す条件分岐を実現する",
      "エラー発生時の例外処理を行う",
      "トランザクションの分離レベルを設定する",
    ],
    correctIndex: 1,
    explanation:
      "CASE式はSQLで条件分岐を実現する構文で、CASE WHEN 条件 THEN 値 ELSE デフォルト値 END のように記述します。SELECT句、WHERE句、ORDER BY句など様々な場所で使用でき、例えばスコアに応じてA/B/C等のランクを付与するといったデータ変換に活用されます。",
  },
  {
    id: "de-050",
    category: "データエンジニアリング力",
    question:
      "SQLのEXISTS句の説明として最も適切なものはどれか？",
    choices: [
      "指定したカラムにNULLでない値が存在するかを確認する",
      "サブクエリの結果が1行以上存在するかどうかを判定する",
      "テーブルが存在するかどうかを確認する",
      "インデックスが存在するかどうかを確認する",
    ],
    correctIndex: 1,
    explanation:
      "EXISTS句はサブクエリの結果セットに1行以上の行が存在するかどうかをブール値で判定します。相関サブクエリと組み合わせて「条件に合致する関連レコードが存在する行のみを取得する」といった用途で使われます。IN句と似た用途で使えますが、大規模データではEXISTSの方がパフォーマンスに優れることがあります。",
  },

  // ===== ビジネス力（追加分） =====
  {
    id: "biz-021",
    category: "ビジネス力",
    question:
      "CAC（Customer Acquisition Cost：顧客獲得コスト）の計算式として正しいものはどれか？",
    choices: [
      "総売上 ÷ 顧客数",
      "マーケティング・営業コストの合計 ÷ 新規獲得顧客数",
      "顧客1人あたりの平均購入金額 × 購入頻度",
      "総利益 ÷ 総コスト",
    ],
    correctIndex: 1,
    explanation:
      "CACは一定期間のマーケティングおよび営業にかかったコストの合計を、その期間に獲得した新規顧客数で割って算出します。LTV（顧客生涯価値）と比較することで、顧客獲得の投資効率を評価でき、一般にLTV/CACの比率が3以上であることが健全な水準とされます。",
  },
  {
    id: "biz-022",
    category: "ビジネス力",
    question:
      "SaaSビジネスにおけるチャーンレート（解約率）の説明として最も適切なものはどれか？",
    choices: [
      "新規顧客が初回購入する割合",
      "一定期間内にサービスを解約または利用を停止した顧客の割合",
      "顧客が他社サービスから乗り換えてくる割合",
      "無料ユーザーが有料プランにアップグレードする割合",
    ],
    correctIndex: 1,
    explanation:
      "チャーンレートは一定期間内にサービスを解約した顧客数を期間開始時の顧客数で割って算出します。サブスクリプションビジネスにおいて最も重要な指標の1つであり、チャーンレートが高いと新規顧客を獲得しても収益が成長しにくくなります。顧客チャーンと収益チャーンの両方を追跡することが重要です。",
  },
  {
    id: "biz-023",
    category: "ビジネス力",
    question:
      "ファネル分析の説明として最も適切なものはどれか？",
    choices: [
      "顧客の属性によってグループ分けして行動を比較する分析",
      "認知から購入に至るまでの各段階での離脱率を可視化し、改善点を特定する分析",
      "時系列でのトレンドを分析する手法",
      "複数のKPIの相関関係を分析する手法",
    ],
    correctIndex: 1,
    explanation:
      "ファネル分析は、ユーザーが認知、興味、検討、購入などの各段階を経る過程で、各ステップでの離脱率（ドロップオフ）を可視化・分析する手法です。漏斗（ファネル）のように段階が進むほど人数が減少する様子を表し、最も離脱が多い段階を特定してコンバージョン率を改善するための施策立案に活用されます。",
  },
  {
    id: "biz-024",
    category: "ビジネス力",
    question:
      "マーケティングにおけるアトリビューション分析の目的として最も適切なものはどれか？",
    choices: [
      "顧客の属性情報を収集・整理する",
      "コンバージョンに至るまでの各マーケティングチャネルの貢献度を評価する",
      "商品の適正価格を決定する",
      "競合他社のマーケティング戦略を分析する",
    ],
    correctIndex: 1,
    explanation:
      "アトリビューション分析は、顧客がコンバージョン（購入や問い合わせ）に至るまでに接触した各マーケティングチャネル（広告、SNS、メールなど）の貢献度を評価する分析手法です。ラストクリック、ファーストクリック、線形、時間減衰など複数のアトリビューションモデルがあり、マーケティング予算の最適配分に活用されます。",
  },
  {
    id: "biz-025",
    category: "ビジネス力",
    question:
      "データリテラシーの説明として最も適切なものはどれか？",
    choices: [
      "高度なプログラミングスキルを持つこと",
      "データを読み、理解し、活用して意思決定やコミュニケーションに役立てる能力",
      "大量のデータを高速に処理する技術力",
      "データベースの設計と管理ができる能力",
    ],
    correctIndex: 1,
    explanation:
      "データリテラシーとは、データを読み取り、意味を理解し、分析結果を批判的に評価して、適切な意思決定やコミュニケーションに活用できる能力を指します。専門的なスキルに限らず、すべてのビジネスパーソンに求められる基礎能力であり、データドリブンな組織文化の構築に不可欠な要素です。",
  },
  {
    id: "biz-026",
    category: "ビジネス力",
    question:
      "あるプロジェクトに500万円を投資し、800万円の利益を得た場合、ROI（投資対効果）は何%か？",
    choices: ["30%", "60%", "160%", "260%"],
    correctIndex: 1,
    explanation:
      "ROI（Return on Investment）は（利益 − 投資額）÷ 投資額 × 100 で計算します。この場合（800万円 − 500万円）÷ 500万円 × 100 = 60%です。ROIはプロジェクトの投資効率を評価する基本的な指標であり、複数の施策を比較して優先順位を決定する際に活用されます。",
  },
  {
    id: "biz-027",
    category: "ビジネス力",
    question:
      "データ分析プロジェクトにおけるステークホルダーマネジメントの説明として最も適切なものはどれか？",
    choices: [
      "プロジェクトの技術的な課題のみを管理する",
      "プロジェクトに関わる利害関係者を特定し、期待や要求を把握して適切にコミュニケーションを行う",
      "プロジェクトの予算管理を行う",
      "チームメンバーの人事評価を行う",
    ],
    correctIndex: 1,
    explanation:
      "ステークホルダーマネジメントは、プロジェクトの利害関係者（経営層、事業部門、IT部門、エンドユーザーなど）を特定し、それぞれの期待、要求、影響力を把握した上で適切なコミュニケーション戦略を実行する活動です。分析プロジェクトでは、ビジネス課題の正確な理解と分析結果の効果的な活用のために特に重要です。",
  },
  {
    id: "biz-028",
    category: "ビジネス力",
    question:
      "データストーリーテリングにおいて最も重要な要素の組み合わせはどれか？",
    choices: [
      "高度な統計手法、大量のデータ、複雑なグラフ",
      "データ、ビジュアル（可視化）、ナラティブ（物語）",
      "プログラミング言語、データベース、クラウド環境",
      "精度、再現性、速度",
    ],
    correctIndex: 1,
    explanation:
      "データストーリーテリングは、データ（事実・根拠）、ビジュアル（わかりやすい可視化）、ナラティブ（文脈と物語）の3要素を組み合わせて、分析結果を聴衆に伝え行動を促す手法です。単にデータを提示するだけでなく、なぜそれが重要なのか、どのようなアクションが必要かを物語として伝えることで、意思決定者の理解と行動につなげます。",
  },
  {
    id: "biz-029",
    category: "ビジネス力",
    question:
      "ビジネスモデルキャンバスの9つの構成要素に含まれないものはどれか？",
    choices: [
      "価値提案（Value Propositions）",
      "顧客セグメント（Customer Segments）",
      "SWOT分析（SWOT Analysis）",
      "収益の流れ（Revenue Streams）",
    ],
    correctIndex: 2,
    explanation:
      "ビジネスモデルキャンバスは、顧客セグメント、価値提案、チャネル、顧客との関係、収益の流れ、リソース、主要活動、パートナー、コスト構造の9つの要素でビジネスモデルを可視化するフレームワークです。SWOT分析は別のフレームワークであり、ビジネスモデルキャンバスの構成要素には含まれません。",
  },
  {
    id: "biz-030",
    category: "ビジネス力",
    question:
      "SWOT分析の4つの要素のうち、内部環境に関する要素の組み合わせとして正しいものはどれか？",
    choices: [
      "強み（Strengths）と機会（Opportunities）",
      "強み（Strengths）と弱み（Weaknesses）",
      "弱み（Weaknesses）と脅威（Threats）",
      "機会（Opportunities）と脅威（Threats）",
    ],
    correctIndex: 1,
    explanation:
      "SWOT分析では、強み（Strengths）と弱み（Weaknesses）が内部環境の要因、機会（Opportunities）と脅威（Threats）が外部環境の要因です。自社の内部資源と外部環境を整理し、戦略の方向性を検討するための基本的なフレームワークとして広く活用されています。",
  },
  {
    id: "biz-031",
    category: "ビジネス力",
    question:
      "OKR（Objectives and Key Results）においてKey Results（主要成果指標）の特徴として最も適切なものはどれか？",
    choices: [
      "定性的で抽象的な目標を設定する",
      "定量的で測定可能な成果指標を設定する",
      "チームメンバーの行動規範を定義する",
      "プロジェクトのタスクリストを作成する",
    ],
    correctIndex: 1,
    explanation:
      "OKRのKey Resultsは、Objective（達成したい目標）の進捗を測るための定量的で測定可能な指標です。例えばObjectiveが「顧客満足度を大幅に向上させる」であれば、Key Resultsは「NPSスコアを50以上にする」「サポート対応時間を平均2時間以内にする」のように具体的に設定します。GoogleやIntelが採用した目標管理フレームワークとして知られています。",
  },
  {
    id: "biz-032",
    category: "ビジネス力",
    question:
      "ウォーターフォール開発とアジャイル開発を比較した場合、ウォーターフォール開発の特徴として最も適切なものはどれか？",
    choices: [
      "短いイテレーションで反復的に開発を進める",
      "要件定義、設計、実装、テストなどの工程を順次進め、前の工程に戻らないことを前提とする",
      "動くソフトウェアを重視し、ドキュメントは最小限にする",
      "変更要求に柔軟に対応することを重視する",
    ],
    correctIndex: 1,
    explanation:
      "ウォーターフォール開発は、要件定義、設計、実装、テスト、運用の各工程を順番に進め、原則として前の工程に戻らない開発手法です。要件が明確で変更が少ないプロジェクトに適していますが、開発後半で要件変更が発生した場合のコストが大きいという課題があります。アジャイル開発は反復的に開発を進め、変化への柔軟な対応を重視します。",
  },
  {
    id: "biz-033",
    category: "ビジネス力",
    question:
      "スクラム開発における「スプリント」の説明として最も適切なものはどれか？",
    choices: [
      "プロジェクト全体の計画を策定するフェーズ",
      "1〜4週間の固定された期間で、計画・開発・レビューを行う反復単位",
      "チーム全員が参加する毎日のミーティング",
      "プロダクトの要件をリスト化したもの",
    ],
    correctIndex: 1,
    explanation:
      "スプリントはスクラム開発の中核となる時間枠で、通常1〜4週間（多くは2週間）の固定期間です。各スプリントではスプリントプランニング、デイリースクラム、開発作業、スプリントレビュー、レトロスペクティブを行い、動作するプロダクトの増分（インクリメント）を作成します。",
  },
  {
    id: "biz-034",
    category: "ビジネス力",
    question:
      "カンバン方式の基本原則として最も適切なものはどれか？",
    choices: [
      "固定期間のイテレーションで作業を区切る",
      "作業の可視化とWIP（仕掛中の作業）制限により流れを最適化する",
      "事前にすべての要件を定義してから開発を開始する",
      "チームの役割を厳密に定義して分業する",
    ],
    correctIndex: 1,
    explanation:
      "カンバン方式は、カンバンボードで作業を可視化し、WIP（Work In Progress：仕掛中の作業）に上限を設けることで、ボトルネックの発見とフローの最適化を図る手法です。スクラムのような固定のイテレーションを持たず、継続的にタスクを流す点が特徴であり、トヨタ生産方式から着想を得たアジャイルの手法の1つです。",
  },
  {
    id: "biz-035",
    category: "ビジネス力",
    question:
      "XAI（Explainable AI：説明可能なAI）が求められる主な理由として最も適切なものはどれか？",
    choices: [
      "AIモデルの処理速度を向上させるため",
      "AIの判断根拠を人間が理解・検証できるようにし、信頼性と透明性を確保するため",
      "AIモデルのデータ量を削減するため",
      "AIモデルの学習時間を短縮するため",
    ],
    correctIndex: 1,
    explanation:
      "XAIはAIモデルの予測や判断の根拠を人間が理解できる形で説明する技術・アプローチです。医療診断や金融審査など、判断理由の説明が求められる領域で特に重要です。代表的な手法にLIME、SHAP、Attention Visualizationなどがあり、EUのAI規則など規制面でもAIの説明可能性が求められるようになっています。",
  },
  {
    id: "biz-036",
    category: "ビジネス力",
    question:
      "Responsible AI（責任あるAI）の主要な原則に含まれないものはどれか？",
    choices: [
      "公平性（Fairness）",
      "透明性（Transparency）",
      "処理速度の最大化（Maximum Speed）",
      "プライバシーとセキュリティ（Privacy & Security）",
    ],
    correctIndex: 2,
    explanation:
      "Responsible AIの主要原則には、公平性、透明性、説明可能性、プライバシーとセキュリティ、安全性、アカウンタビリティ（説明責任）などが含まれます。処理速度の最大化は技術的なパフォーマンスの問題であり、Responsible AIの倫理的原則には含まれません。AIの社会的影響を考慮し、責任ある開発・運用を行うことが求められています。",
  },
  {
    id: "biz-037",
    category: "ビジネス力",
    question:
      "オープンデータの説明として最も適切なものはどれか？",
    choices: [
      "企業の内部データを社内で共有すること",
      "誰もが自由に利用、再配布、加工できる形で公開されたデータ",
      "SNS上で公開されたユーザーの個人情報",
      "有料で提供されるデータサービス",
    ],
    correctIndex: 1,
    explanation:
      "オープンデータは、政府や自治体、研究機関などが、誰もが自由に利用・再配布・加工できるライセンスの下で公開するデータです。日本では政府統計のe-Stat、DATA.GO.JPなどがあり、新たなサービス創出や政策立案の透明性向上、学術研究の促進などに活用されています。",
  },
  {
    id: "biz-038",
    category: "ビジネス力",
    question:
      "プライバシーバイデザインの7原則に含まれる考え方として最も適切なものはどれか？",
    choices: [
      "プライバシー問題が発生してから対策を講じる",
      "システムの設計段階からプライバシー保護を組み込み、事前に対策を講じる",
      "利便性を最優先し、プライバシー保護は最小限にする",
      "個人情報は一律に収集を禁止する",
    ],
    correctIndex: 1,
    explanation:
      "プライバシーバイデザインは、カナダのAnn Cavoukian博士が提唱した概念で、システムやビジネスプロセスの設計段階からプライバシー保護を組み込む予防的アプローチです。GDPRでも「データ保護バイデザイン」として規定されており、事後対応ではなく事前予防、デフォルトでプライバシー保護が有効になる設計が求められます。",
  },
  {
    id: "biz-039",
    category: "ビジネス力",
    question:
      "カスタマージャーニーの説明として最も適切なものはどれか？",
    choices: [
      "顧客のクレーム対応プロセスを定義したもの",
      "顧客がブランドや製品と接触してから購入・利用に至るまでの一連の体験を時系列で可視化したもの",
      "顧客の年齢や性別でセグメント化したもの",
      "顧客の購入金額のランキングを作成したもの",
    ],
    correctIndex: 1,
    explanation:
      "カスタマージャーニーは、顧客がブランドや製品・サービスを認知し、検討、購入、利用、推奨に至るまでの一連の体験を時系列でマッピングしたものです。各タッチポイントでの顧客の行動、思考、感情を可視化することで、顧客体験（CX）の課題を発見し改善施策を立案するために活用されます。",
  },
  {
    id: "biz-040",
    category: "ビジネス力",
    question:
      "センチメント分析（感情分析）の説明として最も適切なものはどれか？",
    choices: [
      "テキストデータからトピックの出現頻度を集計する分析",
      "テキストデータからポジティブ・ネガティブなどの感情や意見の傾向を判定する分析",
      "画像データから人物の表情を認識する分析",
      "音声データの周波数を分析する手法",
    ],
    correctIndex: 1,
    explanation:
      "センチメント分析は、SNSの投稿、レビュー、カスタマーサポートの記録などのテキストデータから、ポジティブ、ネガティブ、ニュートラルなどの感情や意見の傾向を自動的に判定する自然言語処理の手法です。ブランド評判のモニタリング、製品フィードバックの分析、市場動向の把握などビジネスに幅広く活用されています。",
  },
  {
    id: "biz-041",
    category: "ビジネス力",
    question:
      "需要予測にデータサイエンスを活用する際の説明として最も適切なものはどれか？",
    choices: [
      "過去の販売データのみを使い、外部要因は一切考慮しない",
      "過去の販売データに加え、季節性、イベント、天候などの外部要因も考慮して将来の需要を予測する",
      "需要予測では統計モデルは使用せず、担当者の経験のみに依存する",
      "需要予測は製造業でのみ適用可能な手法である",
    ],
    correctIndex: 1,
    explanation:
      "データサイエンスを活用した需要予測では、過去の販売データ（時系列データ）に加え、季節性、曜日、祝日、天候、プロモーション、経済指標などの外部要因を組み合わせて予測モデルを構築します。適切な在庫管理、人員配置、生産計画の最適化につながり、小売、物流、サービス業など幅広い業種で活用されています。",
  },
  {
    id: "biz-042",
    category: "ビジネス力",
    question:
      "データサイエンスを活用した価格最適化（ダイナミックプライシング）の説明として最も適切なものはどれか？",
    choices: [
      "原価に一定の利益率を加算して販売価格を決定する手法",
      "需要、競合価格、在庫状況などのデータに基づいて価格をリアルタイムに最適化する手法",
      "すべての商品を同一価格に統一する手法",
      "値引きを一切行わない価格戦略",
    ],
    correctIndex: 1,
    explanation:
      "ダイナミックプライシングは、需要の変動、競合の価格、在庫状況、顧客セグメント、時間帯などの多様なデータを分析し、収益を最大化するように価格をリアルタイムに調整する手法です。航空券、ホテル、ECサイト、ライドシェアなどで広く採用されており、機械学習を活用して最適な価格帯を予測します。",
  },
  {
    id: "biz-043",
    category: "ビジネス力",
    question:
      "市場セグメンテーションの説明として最も適切なものはどれか？",
    choices: [
      "市場全体に対して画一的なマーケティング施策を実施する",
      "市場を共通のニーズや特性を持つ顧客グループに分割し、それぞれに最適な戦略を立案する",
      "競合企業のシェアを分析する",
      "新規市場への参入タイミングを決定する",
    ],
    correctIndex: 1,
    explanation:
      "市場セグメンテーションは、顧客を人口統計的属性（年齢、性別）、地理的属性、心理的属性（ライフスタイル、価値観）、行動的属性（購買頻度、利用状況）などの基準で分類し、各セグメントに最適なマーケティング戦略を展開する手法です。クラスタリングなどの機械学習手法を活用したデータドリブンなセグメンテーションも広く行われています。",
  },
  {
    id: "biz-044",
    category: "ビジネス力",
    question:
      "クロスセルとアップセルの説明として正しいものはどれか？",
    choices: [
      "クロスセルは上位商品を勧め、アップセルは関連商品を勧める",
      "クロスセルは関連商品や補完商品を勧め、アップセルはより高価格・上位の商品を勧める",
      "クロスセルは新規顧客への販売、アップセルは既存顧客への販売を意味する",
      "クロスセルはBtoBの販売手法、アップセルはBtoCの販売手法である",
    ],
    correctIndex: 1,
    explanation:
      "クロスセルは購入した商品に関連する別の商品を勧める手法（例：スマホ購入者にケースを提案）、アップセルはより高機能・上位グレードの商品を勧める手法（例：標準プランからプレミアムプランへの誘導）です。ECサイトのレコメンデーションエンジンなど、データサイエンスを活用して効果的に実施されています。",
  },
  {
    id: "biz-045",
    category: "ビジネス力",
    question:
      "PDCAサイクルの4つのステップの正しい順序はどれか？",
    choices: [
      "Plan → Do → Act → Check",
      "Plan → Do → Check → Act",
      "Plan → Check → Do → Act",
      "Do → Plan → Check → Act",
    ],
    correctIndex: 1,
    explanation:
      "PDCAサイクルは、Plan（計画）→ Do（実行）→ Check（評価・測定）→ Act（改善）の4ステップを繰り返すことで業務を継続的に改善するフレームワークです。データ分析プロジェクトでは、仮説立案（P）、データ収集・分析の実行（D）、結果の検証・評価（C）、改善策の実施（A）として活用されます。",
  },
  {
    id: "biz-046",
    category: "ビジネス力",
    question:
      "バランススコアカード（BSC）の4つの視点に含まれないものはどれか？",
    choices: [
      "財務の視点",
      "顧客の視点",
      "競合分析の視点",
      "学習と成長の視点",
    ],
    correctIndex: 2,
    explanation:
      "バランススコアカードは、財務の視点、顧客の視点、社内ビジネスプロセスの視点、学習と成長の視点の4つの観点から組織のパフォーマンスを総合的に評価するフレームワークです。財務指標だけでなく非財務指標も含めてバランスよく経営を評価することで、短期的な利益追求と長期的な組織成長の両立を目指します。",
  },
  {
    id: "biz-047",
    category: "ビジネス力",
    question:
      "デザイン思考の5つのプロセスの最初のステップはどれか？",
    choices: [
      "定義（Define）",
      "共感（Empathize）",
      "発想（Ideate）",
      "プロトタイプ（Prototype）",
    ],
    correctIndex: 1,
    explanation:
      "デザイン思考のプロセスは、共感（Empathize）→ 定義（Define）→ 発想（Ideate）→ プロトタイプ（Prototype）→ テスト（Test）の5つのステップで構成されます。最初のステップである共感では、ユーザーの行動を観察しインタビューなどを通じてニーズや課題を深く理解します。人間中心のイノベーション手法として広く活用されています。",
  },
  {
    id: "biz-048",
    category: "ビジネス力",
    question:
      "リーンスタートアップにおけるMVP（Minimum Viable Product）の説明として最も適切なものはどれか？",
    choices: [
      "考えられるすべての機能を実装した完成品",
      "仮説を検証するために必要最小限の機能を持つ製品",
      "市場で最も安価な製品",
      "品質を犠牲にして最速で作られた製品",
    ],
    correctIndex: 1,
    explanation:
      "MVPは、ビジネス仮説を検証するために必要最小限の機能のみを実装した製品です。リーンスタートアップでは、Build（構築）→ Measure（計測）→ Learn（学習）のサイクルを素早く回し、最小限のコストと時間で市場からのフィードバックを得て、ピボット（方向転換）や改善の意思決定を行います。",
  },
  {
    id: "biz-049",
    category: "ビジネス力",
    question:
      "組織のデータ利活用の成熟度モデルにおいて、最も成熟度が高い段階の特徴として最も適切なものはどれか？",
    choices: [
      "Excelで基本的な集計やグラフ作成を行う段階",
      "部門ごとに個別にデータ分析を行う段階",
      "データに基づく予測と最適化が全社的に意思決定プロセスに組み込まれている段階",
      "BIツールを導入してダッシュボードを作成する段階",
    ],
    correctIndex: 2,
    explanation:
      "データ利活用の成熟度モデルでは、最高段階では組織全体でデータに基づく予測分析や最適化が意思決定プロセスに組み込まれ、データドリブンな文化が定着している状態を指します。初期段階のExcel集計、中間段階のBIダッシュボード導入から段階的に成熟し、最終的にはAI・機械学習を活用した予測・処方的分析が全社的に運用される状態が最も成熟した段階です。",
  },
  {
    id: "biz-050",
    category: "ビジネス力",
    question:
      "アルゴリズムバイアスの説明として最も適切なものはどれか？",
    choices: [
      "アルゴリズムの計算速度が遅いこと",
      "学習データの偏りや設計上の問題により、AIの判断が特定のグループに対して不公平な結果をもたらすこと",
      "アルゴリズムが複雑すぎて理解できないこと",
      "アルゴリズムのバージョンが古いこと",
    ],
    correctIndex: 1,
    explanation:
      "アルゴリズムバイアスは、学習データに含まれる歴史的な偏り、データ収集過程の偏り、特徴量選択の問題などにより、AIシステムが特定の人種、性別、年齢などのグループに対して不公平な判断を下してしまう現象です。採用AI、ローン審査、刑事司法などの分野で問題が顕在化しており、公平性の指標によるモニタリングやバイアス緩和手法の適用がResponsible AIの観点から重要視されています。",
  },
];
