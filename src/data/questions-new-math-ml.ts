import type { Question } from "../types";

export const newMathMlQuestions: Question[] = [
  // ===== データサイエンス力（数学・統計 追加分） =====
  {
    id: "math-021",
    category: "データサイエンス力",
    question: "中央値（メジアン）の特徴として正しいものはどれか？",
    choices: [
      "データの合計をデータ数で割った値である",
      "データを大きさ順に並べたときの中央の値であり、外れ値の影響を受けにくい",
      "最も頻繁に出現する値である",
      "常に平均値と一致する",
    ],
    correctIndex: 1,
    explanation:
      "中央値はデータを昇順に並べたときの中央の値で、外れ値に対してロバスト（頑健）な指標です。平均値は外れ値に引っ張られやすいため、歪んだ分布では中央値のほうが代表値として適切な場合があります。最頻値は最も頻繁に出現する値です。",
  },
  {
    id: "math-022",
    category: "データサイエンス力",
    question: "二項分布 B(n, p) の分散はどれか？",
    choices: ["np", "np(1-p)", "n²p", "p(1-p)"],
    correctIndex: 1,
    explanation:
      "二項分布B(n, p)の期待値はnp、分散はnp(1-p)です。二項分布はn回の独立なベルヌーイ試行における成功回数の分布で、各試行の成功確率がpのときに適用されます。",
  },
  {
    id: "math-023",
    category: "データサイエンス力",
    question: "指数分布の特徴として正しいものはどれか？",
    choices: [
      "離散型の確率分布である",
      "事象が発生するまでの待ち時間をモデル化する連続型分布で、無記憶性を持つ",
      "左右対称なベル型の分布である",
      "値が0から1の範囲のみを取る",
    ],
    correctIndex: 1,
    explanation:
      "指数分布はポアソン過程における次の事象が発生するまでの待ち時間を表す連続型確率分布です。無記憶性（memoryless property）という特徴があり、すでに経過した時間が今後の待ち時間に影響しません。パラメータλは事象の発生率を表します。",
  },
  {
    id: "math-024",
    category: "データサイエンス力",
    question: "連続一様分布 U(a, b) の期待値と分散の組み合わせとして正しいものはどれか？",
    choices: [
      "期待値：(a+b)/2、分散：(b-a)²/12",
      "期待値：(a+b)/2、分散：(b-a)/12",
      "期待値：ab/2、分散：(b-a)²/6",
      "期待値：(b-a)/2、分散：(a+b)²/12",
    ],
    correctIndex: 0,
    explanation:
      "連続一様分布U(a, b)はa以上b以下の範囲で確率密度が一定な分布です。期待値は(a+b)/2、分散は(b-a)²/12で計算されます。乱数生成の基礎として重要な分布です。",
  },
  {
    id: "math-025",
    category: "データサイエンス力",
    question: "95%信頼区間の正しい解釈はどれか？",
    choices: [
      "母数が95%の確率でこの区間に含まれる",
      "同じ方法で標本を繰り返し取ったとき、約95%の信頼区間が母数を含む",
      "データの95%がこの区間に含まれる",
      "この区間の幅が母数の95%に相当する",
    ],
    correctIndex: 1,
    explanation:
      "信頼区間は母数が区間に入る確率ではなく、同じ手順で何度も標本抽出と区間推定を行った場合に、構成された区間の約95%が真の母数を含むという頻度的な解釈が正しいです。母数は固定値であり確率的に変動するものではありません。",
  },
  {
    id: "math-026",
    category: "データサイエンス力",
    question: "分散分析（ANOVA）を使う場面として最も適切なものはどれか？",
    choices: [
      "2つのカテゴリカル変数の独立性を検定する場合",
      "3群以上の母平均の差を同時に検定する場合",
      "1つの変数の正規性を検定する場合",
      "2変数間の相関を検定する場合",
    ],
    correctIndex: 1,
    explanation:
      "分散分析（ANOVA: Analysis of Variance）は3群以上の母平均に差があるかを検定する手法です。群間変動と群内変動の比であるF統計量を用いて検定を行います。2群間の比較にはt検定を用い、3群以上ではANOVAを使います。",
  },
  {
    id: "math-027",
    category: "データサイエンス力",
    question: "スピアマンの順位相関係数の特徴として正しいものはどれか？",
    choices: [
      "データが正規分布に従う場合にのみ使える",
      "データの順位（ランク）に基づいて算出し、単調な関連性を評価できる",
      "値の範囲は0から1である",
      "連続データのみに適用でき、順序データには適用できない",
    ],
    correctIndex: 1,
    explanation:
      "スピアマンの順位相関係数はデータを順位に変換して算出するノンパラメトリックな相関係数です。外れ値の影響を受けにくく、線形でなくても単調な関連性を評価できます。値の範囲はピアソン相関と同じ-1から1です。",
  },
  {
    id: "math-028",
    category: "データサイエンス力",
    question: "情報理論におけるエントロピー H(X) の説明として正しいものはどれか？",
    choices: [
      "確率変数Xの期待値を表す",
      "確率変数Xの不確実さ（平均情報量）を表す",
      "確率変数Xの分散を対数変換した値である",
      "確率変数Xの最大値と最小値の差を表す",
    ],
    correctIndex: 1,
    explanation:
      "エントロピーH(X) = -Σ p(x) log p(x) は確率分布の不確実さ（ランダムさ）の指標です。全事象が等確率のとき最大となり、1つの事象が確実に起きる場合は0になります。決定木の分岐基準やクロスエントロピー損失関数の基礎となる重要な概念です。",
  },
  {
    id: "math-029",
    category: "データサイエンス力",
    question: "決定係数R²の説明として正しいものはどれか？",
    choices: [
      "相関係数rと同じ値を取る",
      "回帰モデルが目的変数の変動をどれだけ説明できるかを示し、0から1の範囲を取る",
      "回帰係数の有意性を直接示す指標である",
      "説明変数の数を増やすと必ず減少する",
    ],
    correctIndex: 1,
    explanation:
      "決定係数R²は全変動のうち回帰モデルで説明できる割合を示し、1に近いほど当てはまりが良いことを意味します。ただし説明変数を増やすとR²は増加する傾向があるため、自由度調整済みR²を用いることが推奨されます。",
  },
  {
    id: "math-030",
    category: "データサイエンス力",
    question: "母集団と標本の関係について正しい記述はどれか？",
    choices: [
      "標本は母集団と常に同じ分布を持つ",
      "母集団から無作為抽出した標本を用いて母集団のパラメータを推定する",
      "母集団のサイズは標本のサイズより常に小さい",
      "標本平均は常に母平均に一致する",
    ],
    correctIndex: 1,
    explanation:
      "統計的推測では、調査対象全体（母集団）から一部のデータ（標本）を無作為抽出し、その標本の統計量から母集団のパラメータ（母平均、母分散など）を推定します。無作為抽出により標本の偏りを防ぐことが重要です。",
  },
  {
    id: "math-031",
    category: "データサイエンス力",
    question: "大数の法則の説明として正しいものはどれか？",
    choices: [
      "標本サイズが大きくなると標本平均の分布が正規分布に近づく",
      "標本サイズが大きくなると標本平均が母平均に確率的に収束する",
      "標本サイズが大きくなると分散が無限大に発散する",
      "データ数が多いほど外れ値が増える",
    ],
    correctIndex: 1,
    explanation:
      "大数の法則は、標本サイズnを大きくしていくと標本平均が母平均（期待値）に確率的に収束するという定理です。中心極限定理が分布の形状に言及するのに対し、大数の法則は収束に関する定理である点に注意が必要です。",
  },
  {
    id: "math-032",
    category: "データサイエンス力",
    question: "F検定の主な用途はどれか？",
    choices: [
      "2群の平均値の差を検定する",
      "2つの母集団の分散の比が等しいかどうかを検定する",
      "カテゴリカル変数の独立性を検定する",
      "データが正規分布に従うかどうかを検定する",
    ],
    correctIndex: 1,
    explanation:
      "F検定は2つの母集団の分散の比が1であるか（等分散であるか）を検定します。F統計量は2つの標本分散の比として計算されF分布に従います。t検定を行う前の等分散性の確認にも使用されます。",
  },
  {
    id: "math-033",
    category: "データサイエンス力",
    question: "箱ひげ図における四分位範囲（IQR）の定義はどれか？",
    choices: [
      "最大値と最小値の差",
      "第3四分位数（Q3）と第1四分位数（Q1）の差",
      "平均値からの標準偏差の範囲",
      "中央値からの平均偏差",
    ],
    correctIndex: 1,
    explanation:
      "四分位範囲（IQR）はQ3 - Q1で計算され、データの中央50%が含まれる範囲を示します。箱ひげ図ではQ1からQ3が箱として描かれ、Q1 - 1.5×IQR未満またはQ3 + 1.5×IQR超のデータは外れ値として表示されます。",
  },
  {
    id: "math-034",
    category: "データサイエンス力",
    question: "ベイズ推定における共役事前分布の説明として正しいものはどれか？",
    choices: [
      "事後分布が常に一様分布になる事前分布のこと",
      "事前分布と事後分布が同じ分布族に属するような事前分布のこと",
      "尤度関数と同じ分布になる事前分布のこと",
      "情報を含まない無情報事前分布の別名",
    ],
    correctIndex: 1,
    explanation:
      "共役事前分布とは、尤度関数と組み合わせたとき事後分布が事前分布と同じ分布族になるような事前分布のことです。例えば二項分布の尤度に対してベータ分布が共役事前分布となり、事後分布もベータ分布になります。計算が解析的に行えるという利点があります。",
  },
  {
    id: "math-035",
    category: "データサイエンス力",
    question: "マルコフ連鎖の基本的な性質として正しいものはどれか？",
    choices: [
      "過去の全ての状態に依存して次の状態が決まる",
      "現在の状態のみに依存して次の状態が確率的に決まる（マルコフ性）",
      "状態は常に一方向にのみ遷移する",
      "全ての状態への遷移確率が等しい",
    ],
    correctIndex: 1,
    explanation:
      "マルコフ連鎖はマルコフ性（無記憶性）を持ち、次の状態が現在の状態のみに依存し過去の履歴には依存しません。遷移確率行列で状態間の遷移を表現します。PageRankアルゴリズムやMCMC法の基礎となる重要な概念です。",
  },
  {
    id: "math-036",
    category: "データサイエンス力",
    question: "モンテカルロ法の説明として正しいものはどれか？",
    choices: [
      "微分方程式を解析的に解く手法",
      "乱数を用いたシミュレーションにより数値的な近似解を求める手法",
      "データを格子状に分割して探索する決定論的手法",
      "最急降下法の一種",
    ],
    correctIndex: 1,
    explanation:
      "モンテカルロ法は乱数を大量に発生させてシミュレーションを繰り返し、確率的に解を近似する手法です。円周率の推定、積分の近似計算、ベイズ推定におけるMCMC法など幅広い応用があります。試行回数を増やすほど精度が向上します。",
  },
  {
    id: "math-037",
    category: "データサイエンス力",
    question: "検定力（検出力、1-β）の説明として正しいものはどれか？",
    choices: [
      "帰無仮説が真であるときにそれを正しく採択する確率",
      "帰無仮説が偽であるときにそれを正しく棄却する確率",
      "有意水準αと同じ値",
      "p値の逆数",
    ],
    correctIndex: 1,
    explanation:
      "検定力（1-β）は対立仮説が正しいとき（帰無仮説が偽のとき）に帰無仮説を正しく棄却できる確率です。検定力はサンプルサイズ、効果量、有意水準に依存します。一般的に0.8以上の検定力が望ましいとされています。",
  },
  {
    id: "math-038",
    category: "データサイエンス力",
    question: "多重比較におけるボンフェローニ補正の方法はどれか？",
    choices: [
      "サンプルサイズを検定回数で割る",
      "有意水準αを検定回数で割り、各検定の有意水準とする",
      "p値に検定回数を掛けて調整する方法で、αを変更しない",
      "検定回数に関わらず有意水準を0.01に固定する",
    ],
    correctIndex: 1,
    explanation:
      "ボンフェローニ補正は、複数の検定を同時に行う際に全体の第1種の過誤率がαを超えないよう、各検定の有意水準をα/m（mは検定回数）に調整する方法です。保守的な方法であり、検定回数が多いと検出力が低下する欠点があります。",
  },
  {
    id: "math-039",
    category: "データサイエンス力",
    question: "効果量（Cohenのd）の説明として正しいものはどれか？",
    choices: [
      "p値を標準化した指標",
      "2群の平均値の差をプールされた標準偏差で割った標準化された差の指標",
      "サンプルサイズに比例して大きくなる指標",
      "相関係数の絶対値と同一の指標",
    ],
    correctIndex: 1,
    explanation:
      "Cohenのdは2群の平均値の差をプールされた標準偏差で割って標準化した効果量の指標です。一般にd=0.2で小さい効果、d=0.5で中程度の効果、d=0.8で大きい効果と判断されます。p値がサンプルサイズに依存するのに対し、効果量は実質的な差の大きさを示します。",
  },
  {
    id: "math-040",
    category: "データサイエンス力",
    question: "ブートストラップ法の説明として正しいものはどれか？",
    choices: [
      "母集団から繰り返し標本を抽出する方法",
      "手元の標本データから復元抽出を繰り返し、統計量の分布を推定する方法",
      "テストデータを用いてモデルの性能を検証する方法",
      "標本を等分割して交互に検証する方法",
    ],
    correctIndex: 1,
    explanation:
      "ブートストラップ法は、手元の標本データから復元抽出（同じデータが再度選ばれることを許す抽出）を繰り返してリサンプリングを行い、統計量の分布や信頼区間を推定するノンパラメトリックな手法です。理論的な分布が不明な場合に特に有用です。",
  },
  {
    id: "math-041",
    category: "データサイエンス力",
    question: "尤度比検定の説明として正しいものはどれか？",
    choices: [
      "2つの標本の平均値の比を検定する手法",
      "帰無仮説の下での最大尤度と対立仮説の下での最大尤度の比に基づいて検定する手法",
      "尤度関数の微分が0になる点を求める手法",
      "ベイズファクターと同じ概念",
    ],
    correctIndex: 1,
    explanation:
      "尤度比検定は、制約のあるモデル（帰無仮説）と制約のないモデル（対立仮説）の最大尤度の比（尤度比）を検定統計量として用います。-2log(尤度比)は漸近的にカイ二乗分布に従い、モデル比較に広く使用されます。",
  },
  {
    id: "math-042",
    category: "データサイエンス力",
    question: "特異値分解（SVD）の説明として正しいものはどれか？",
    choices: [
      "正方行列のみに適用可能な分解手法",
      "任意の行列をU・Σ・Vᵀの3つの行列の積に分解する手法",
      "行列の固有値を対角成分に並べた分解",
      "逆行列を効率的に計算するための手法",
    ],
    correctIndex: 1,
    explanation:
      "特異値分解（SVD）は任意のm×n行列AをA = UΣVᵀと分解します。Uとは直交行列、Σは特異値を対角成分に持つ対角行列です。PCA、推薦システム、データ圧縮、潜在意味解析など多くの応用があります。",
  },
  {
    id: "math-043",
    category: "データサイエンス力",
    question: "行列のランク（階数）の説明として正しいものはどれか？",
    choices: [
      "行列の全要素の合計値",
      "行列の線形独立な行（または列）ベクトルの最大数",
      "行列の行数と列数の和",
      "行列の対角成分の数",
    ],
    correctIndex: 1,
    explanation:
      "行列のランクは線形独立な行ベクトル（または列ベクトル）の最大個数であり、行列が持つ情報の次元数を表します。ランクが行列の行数・列数の小さい方に等しいときフルランクといい、連立方程式の解の存在・一意性の判定などに使われます。",
  },
  {
    id: "math-044",
    category: "データサイエンス力",
    question: "多変数関数 f(x) の勾配ベクトル ∇f とヘッセ行列 H の関係として正しいものはどれか？",
    choices: [
      "勾配ベクトルはヘッセ行列の固有値で構成される",
      "勾配ベクトルは各変数についての1階偏微分のベクトル、ヘッセ行列は2階偏微分で構成される行列である",
      "ヘッセ行列は勾配ベクトルの転置に等しい",
      "勾配ベクトルとヘッセ行列は常に同じ次元を持つ",
    ],
    correctIndex: 1,
    explanation:
      "勾配ベクトル∇fは各変数の1階偏微分を並べたベクトルで、関数の最も急な増加方向を示します。ヘッセ行列Hは2階偏微分で構成される行列で、関数の曲率の情報を持ちます。ニュートン法などの最適化手法でヘッセ行列が活用されます。",
  },
  {
    id: "math-045",
    category: "データサイエンス力",
    question: "凸最適化問題の特徴として正しいものはどれか？",
    choices: [
      "複数の局所最適解が存在し、大域最適解の発見が困難である",
      "局所最適解が大域最適解と一致するため、効率的に最適解が求まる",
      "目的関数が常に線形関数である",
      "制約条件を設定できない",
    ],
    correctIndex: 1,
    explanation:
      "凸最適化問題では目的関数が凸関数であり、実行可能領域が凸集合であるため、局所最適解が大域最適解に一致します。そのため効率的なアルゴリズムで最適解を保証して求めることができ、機械学習の多くの問題の基盤となっています。",
  },
  {
    id: "math-046",
    category: "データサイエンス力",
    question: "AIC（赤池情報量規準）の説明として正しいものはどれか？",
    choices: [
      "モデルの精度のみを評価する指標",
      "モデルの当てはまりの良さとパラメータ数の複雑さのバランスを評価し、値が小さいほど良いモデルとする指標",
      "サンプルサイズが大きいほど必ず減少する指標",
      "値が大きいほど良いモデルであることを示す指標",
    ],
    correctIndex: 1,
    explanation:
      "AIC = -2ln(L) + 2k（Lは最大尤度、kはパラメータ数）で計算され、モデルの当てはまりの良さ（尤度）と複雑さ（パラメータ数）のトレードオフを評価します。AICが小さいモデルほど良いと判断され、過学習を防ぎながらモデル選択を行えます。",
  },
  {
    id: "math-047",
    category: "データサイエンス力",
    question: "同時分布と周辺分布の関係について正しいものはどれか？",
    choices: [
      "周辺分布は同時分布を条件付けして得られる分布である",
      "周辺分布は同時分布を一方の変数について和（積分）をとることで得られる",
      "同時分布は周辺分布の差として求められる",
      "同時分布と周辺分布は常に同じ分布型になる",
    ],
    correctIndex: 1,
    explanation:
      "2変数の同時分布f(x, y)から、一方の変数について和（離散の場合）または積分（連続の場合）をとることで、他方の変数の周辺分布が得られます。例えばf_X(x) = Σ_y f(x, y)です。同時分布から条件付き分布を得る場合は周辺分布で割ります。",
  },
  {
    id: "math-048",
    category: "データサイエンス力",
    question: "確率密度関数（PDF）と累積分布関数（CDF）の関係として正しいものはどれか？",
    choices: [
      "PDFはCDFの2階微分である",
      "CDFはPDFを積分したもので、CDFを微分するとPDFが得られる",
      "PDFとCDFは常に同じ形状のグラフになる",
      "CDFの値は負になることがある",
    ],
    correctIndex: 1,
    explanation:
      "累積分布関数F(x) = P(X ≤ x)はPDFを−∞からxまで積分した値です。逆にCDFを微分するとPDFが得られます。CDFは単調非減少関数で0から1の範囲の値をとり、F(−∞)=0、F(+∞)=1という性質があります。",
  },
  {
    id: "math-049",
    category: "データサイエンス力",
    question: "幾何分布が表す事象として正しいものはどれか？",
    choices: [
      "n回の試行における成功回数",
      "成功確率pのベルヌーイ試行で初めて成功するまでの試行回数",
      "単位時間あたりの事象の発生回数",
      "事象が起きるまでの連続的な待ち時間",
    ],
    correctIndex: 1,
    explanation:
      "幾何分布は成功確率pの独立なベルヌーイ試行を繰り返したとき、初めて成功するまでの試行回数（または失敗回数）の分布です。期待値は1/p（試行回数の定義の場合）であり、離散分布の中で唯一無記憶性を持つ分布です。",
  },
  {
    id: "math-050",
    category: "データサイエンス力",
    question: "負の二項分布の説明として正しいものはどれか？",
    choices: [
      "二項分布の確率に負の符号をつけた分布",
      "成功確率pのベルヌーイ試行でr回目の成功が得られるまでの試行回数の分布",
      "負の値のみを取る離散分布",
      "ポアソン分布の特殊ケース",
    ],
    correctIndex: 1,
    explanation:
      "負の二項分布は成功確率pの独立なベルヌーイ試行でr回の成功を得るまでの試行回数（または失敗回数）の分布です。r=1の場合は幾何分布に一致します。二項分布は試行回数を固定して成功回数の分布を考えるのに対し、負の二項分布は成功回数を固定して試行回数の分布を考えます。",
  },

  // ===== 機械学習（追加分） =====
  {
    id: "ml-021",
    category: "データサイエンス力",
    question: "ロジスティック回帰の説明として正しいものはどれか？",
    choices: [
      "連続値を予測する回帰手法である",
      "シグモイド関数を用いて確率を出力し、二値分類を行う手法である",
      "決定木の一種である",
      "教師なし学習に分類される手法である",
    ],
    correctIndex: 1,
    explanation:
      "ロジスティック回帰は線形結合にシグモイド関数を適用して0から1の確率値を出力し、分類を行う教師あり学習の手法です。名前に「回帰」とありますが分類モデルであり、モデルの解釈性が高く、特徴量の寄与を係数として解釈できる利点があります。",
  },
  {
    id: "ml-022",
    category: "データサイエンス力",
    question: "ナイーブベイズ分類器の「ナイーブ（素朴）」とは何を仮定しているか？",
    choices: [
      "全ての特徴量が同じ重要度を持つこと",
      "各特徴量が与えられたクラスの下で条件付き独立であること",
      "データが正規分布に従うこと",
      "学習データに誤りが含まれないこと",
    ],
    correctIndex: 1,
    explanation:
      "ナイーブベイズは各特徴量がクラスラベルの下で条件付き独立であるという「素朴な」仮定を置きます。現実にはこの仮定が成り立たないことが多いですが、テキスト分類やスパムフィルタなどで実用的に高い性能を発揮します。計算コストが低く高速に学習できることも特長です。",
  },
  {
    id: "ml-023",
    category: "データサイエンス力",
    question: "決定木の剪定（プルーニング）を行う目的はどれか？",
    choices: [
      "学習データへの適合度を高めるため",
      "過学習を抑制し、モデルの汎化性能を向上させるため",
      "決定木の深さを増やして複雑なパターンを捉えるため",
      "特徴量の数を増やすため",
    ],
    correctIndex: 1,
    explanation:
      "剪定（プルーニング）は決定木の不要な枝を削除して木を単純化し、過学習を防ぐ手法です。事前剪定（pre-pruning）は木の成長中に制限を加え、事後剪定（post-pruning）は完成した木から不要な枝を除去します。コスト複雑度剪定（CCP）が代表的な手法です。",
  },
  {
    id: "ml-024",
    category: "データサイエンス力",
    question: "ランダムフォレストがバギングに加えて行う工夫はどれか？",
    choices: [
      "各決定木で全ての特徴量を使用する",
      "各決定木の各分岐で特徴量のランダムなサブセットから最良の分割を選択する",
      "決定木を直列に接続して逐次学習する",
      "各決定木の深さを1に制限する",
    ],
    correctIndex: 1,
    explanation:
      "ランダムフォレストはバギング（データのブートストラップサンプリング）に加え、各分岐点で特徴量のランダムなサブセットを選んで分割を行います。これにより各決定木間の相関を低減し、アンサンブルの分散をさらに小さくする効果があります。",
  },
  {
    id: "ml-025",
    category: "データサイエンス力",
    question: "XGBoostの特徴として正しいものはどれか？",
    choices: [
      "ランダムフォレストと同じくバギングに基づく手法である",
      "正則化項を目的関数に含み、2次のテイラー展開で勾配ブースティングを効率化した手法である",
      "ニューラルネットワークの一種である",
      "教師なし学習のみに使用できる手法である",
    ],
    correctIndex: 1,
    explanation:
      "XGBoost（eXtreme Gradient Boosting）は勾配ブースティングを改良した手法で、目的関数に正則化項（L1・L2）を含み過学習を抑制します。2次のテイラー展開を利用した効率的な損失関数の最適化、欠損値の自動処理、並列計算などの機能を備え、テーブルデータのコンペティションで広く使われています。",
  },
  {
    id: "ml-026",
    category: "データサイエンス力",
    question: "DBSCANクラスタリングの特徴として正しいものはどれか？",
    choices: [
      "事前にクラスタ数を指定する必要がある",
      "密度に基づくクラスタリングで、任意の形状のクラスタを検出でき、ノイズ点を自動識別できる",
      "全てのデータ点が必ずいずれかのクラスタに属する",
      "ユークリッド距離のみに対応する",
    ],
    correctIndex: 1,
    explanation:
      "DBSCAN（Density-Based Spatial Clustering of Applications with Noise）は密度ベースのクラスタリング手法です。k-meansと異なりクラスタ数の事前指定が不要で、任意の形状のクラスタを検出でき、低密度領域の点をノイズ（外れ値）として扱えます。εとMinPtsの2つのパラメータを設定します。",
  },
  {
    id: "ml-027",
    category: "データサイエンス力",
    question: "階層的クラスタリングの特徴として正しいものはどれか？",
    choices: [
      "データをランダムに分割して反復的にクラスタを改善する",
      "データの結合（または分割）過程をデンドログラム（樹形図）で視覚化でき、任意の段階でクラスタを取得できる",
      "クラスタ数を事前に必ず指定する必要がある",
      "大規模データに対して最も計算効率が良い手法である",
    ],
    correctIndex: 1,
    explanation:
      "階層的クラスタリングは凝集型（ボトムアップ）と分割型（トップダウン）があり、結合過程をデンドログラムで表現できます。デンドログラムを任意の高さで切断することで異なる数のクラスタを得られます。ただし計算量がO(n²)以上であり大規模データには不向きです。",
  },
  {
    id: "ml-028",
    category: "データサイエンス力",
    question: "t-SNE（t-distributed Stochastic Neighbor Embedding）の主な用途はどれか？",
    choices: [
      "教師あり学習による分類",
      "高次元データの2次元または3次元への非線形次元削減と可視化",
      "時系列データの予測",
      "テキストデータの前処理",
    ],
    correctIndex: 1,
    explanation:
      "t-SNEは高次元データの局所的な構造を保持しながら2-3次元に非線形に次元削減する可視化手法です。高次元空間と低次元空間でのデータ点間の確率分布のKLダイバージェンスを最小化します。クラスタ構造の視覚的な探索に有用ですが、大域的な距離関係は保持されにくい点に注意が必要です。",
  },
  {
    id: "ml-029",
    category: "データサイエンス力",
    question: "オートエンコーダの基本的な構造として正しいものはどれか？",
    choices: [
      "生成器と識別器の2つのネットワークで構成される",
      "エンコーダで入力を低次元に圧縮し、デコーダで元の入力を復元するネットワーク構造",
      "入力層と出力層のみで中間層を持たないネットワーク",
      "畳み込み層とプーリング層のみで構成されるネットワーク",
    ],
    correctIndex: 1,
    explanation:
      "オートエンコーダはエンコーダ（入力→低次元表現）とデコーダ（低次元表現→復元出力）から構成される教師なし学習のニューラルネットワークです。入力と出力が同じになるよう学習し、中間のボトルネック層でデータの本質的な特徴を圧縮して学習します。次元削減、特徴抽出、異常検知に活用されます。",
  },
  {
    id: "ml-030",
    category: "データサイエンス力",
    question: "GAN（敵対的生成ネットワーク）の学習の仕組みとして正しいものはどれか？",
    choices: [
      "教師データのラベルを用いて分類精度を最大化する",
      "生成器（Generator）と識別器（Discriminator）が互いに競い合いながら学習する",
      "入力データを圧縮して復元する学習を行う",
      "報酬関数を最大化するように行動方策を最適化する",
    ],
    correctIndex: 1,
    explanation:
      "GANは生成器（偽データを生成）と識別器（本物と偽物を判別）が敵対的に学習するフレームワークです。生成器は識別器を騙せるようにリアルなデータの生成を、識別器は本物と偽物をより正確に見分けるよう学習します。画像生成、データ拡張、スタイル変換など幅広い応用があります。",
  },
  {
    id: "ml-031",
    category: "データサイエンス力",
    question: "バッチ正規化（Batch Normalization）の効果として正しいものはどれか？",
    choices: [
      "バッチサイズを自動的に最適化する",
      "各層の入力の分布を正規化して学習を安定化・高速化する",
      "重みの初期値を正規分布で初期化する",
      "データの前処理として入力データを正規化する",
    ],
    correctIndex: 1,
    explanation:
      "バッチ正規化はミニバッチごとに各層の入力を平均0・分散1に正規化し、学習可能なスケール・シフトパラメータで変換する手法です。内部共変量シフトを軽減し、学習の安定化・高速化を実現します。勾配消失問題の緩和やより大きな学習率の使用を可能にする効果もあります。",
  },
  {
    id: "ml-032",
    category: "データサイエンス力",
    question: "学習率スケジューリングの目的として正しいものはどれか？",
    choices: [
      "バッチサイズを学習の進行に合わせて変更するため",
      "学習の進行に伴い学習率を調整し、収束性能を向上させるため",
      "モデルのパラメータ数を動的に変更するため",
      "訓練データの順序を変更するため",
    ],
    correctIndex: 1,
    explanation:
      "学習率スケジューリングは学習の進行に応じて学習率を変化させる手法です。初期は大きな学習率で素早く探索し、後半に学習率を下げて細かく収束させます。ステップ減衰、コサインアニーリング、ウォームアップ付き減衰など様々な戦略があります。",
  },
  {
    id: "ml-033",
    category: "データサイエンス力",
    question: "データ拡張（Data Augmentation）の説明として正しいものはどれか？",
    choices: [
      "新しいデータソースからデータを収集する手法",
      "既存の訓練データに変換（回転、反転、ノイズ追加等）を施して訓練データを増やす手法",
      "テストデータの量を増やす手法",
      "特徴量の次元数を増やす手法",
    ],
    correctIndex: 1,
    explanation:
      "データ拡張は既存の訓練データに対して回転、反転、拡大縮小、色調変換、ノイズ付加などの変換を施して仮想的にデータ量を増やす手法です。過学習の抑制とモデルの汎化性能向上に効果があり、特に画像認識分野で広く使用されています。",
  },
  {
    id: "ml-034",
    category: "データサイエンス力",
    question: "特徴量エンジニアリングの説明として正しいものはどれか？",
    choices: [
      "モデルのハイパーパラメータを調整する作業",
      "ドメイン知識を活用してモデルの予測に有用な特徴量を作成・選択・変換する作業",
      "データベースの設計を最適化する作業",
      "テストデータを作成する作業",
    ],
    correctIndex: 1,
    explanation:
      "特徴量エンジニアリングは、生データから機械学習モデルの予測に有用な特徴量を作成・選択・変換する作業です。例えば日時データからの曜日抽出、テキストのTF-IDF変換、カテゴリ変数のエンコーディングなどが含まれます。モデルの性能を大きく左右する重要な工程です。",
  },
  {
    id: "ml-035",
    category: "データサイエンス力",
    question: "特徴量の標準化（Standardization）と正規化（Min-Max Normalization）の違いとして正しいものはどれか？",
    choices: [
      "標準化はデータを0-1の範囲に変換し、正規化は平均0・標準偏差1に変換する",
      "標準化は平均0・標準偏差1に変換し、正規化（Min-Max）はデータを0-1の範囲に変換する",
      "標準化と正規化は同じ処理を指す",
      "標準化はカテゴリ変数、正規化は連続変数に対して行う",
    ],
    correctIndex: 1,
    explanation:
      "標準化（Z-score normalization）はデータから平均を引き標準偏差で割ることで平均0・標準偏差1に変換します。Min-Max正規化はデータを最小値0・最大値1の範囲にスケーリングします。SVMやk-NNなど距離ベースの手法では特徴量のスケーリングが特に重要です。",
  },
  {
    id: "ml-036",
    category: "データサイエンス力",
    question: "不均衡データへの対処法であるSMOTEの説明として正しいものはどれか？",
    choices: [
      "多数クラスのデータを削除してバランスをとる手法",
      "少数クラスのデータ間を線形補間して新しいサンプルを合成的に生成する手法",
      "コスト関数の重みを調整する手法",
      "評価指標を変更する手法",
    ],
    correctIndex: 1,
    explanation:
      "SMOTE（Synthetic Minority Over-sampling Technique）は少数クラスの既存サンプルのk近傍を利用して、データ間を線形補間することで新たな合成サンプルを生成するオーバーサンプリング手法です。単純な複製と異なり多様なサンプルを生成でき、過学習のリスクを低減します。",
  },
  {
    id: "ml-037",
    category: "データサイエンス力",
    question: "ハイパーパラメータチューニングの手法として、ベイズ最適化の利点はどれか？",
    choices: [
      "全てのハイパーパラメータの組み合わせを網羅的に探索する",
      "過去の探索結果を活用して次に試すパラメータを効率的に選択する",
      "パラメータをランダムに選択して探索する",
      "ハイパーパラメータを自動的に固定値に設定する",
    ],
    correctIndex: 1,
    explanation:
      "ベイズ最適化は過去の評価結果から目的関数の代理モデル（ガウス過程など）を構築し、獲得関数に基づいて次に試すパラメータを効率的に選択します。グリッドサーチ（網羅的探索）やランダムサーチに比べて少ない試行回数で良好なパラメータを見つけられる傾向があります。",
  },
  {
    id: "ml-038",
    category: "データサイエンス力",
    question: "混同行列（Confusion Matrix）から読み取れない情報はどれか？",
    choices: [
      "真陽性（TP）と偽陽性（FP）の件数",
      "真陰性（TN）と偽陰性（FN）の件数",
      "最適な分類閾値",
      "正解率（Accuracy）",
    ],
    correctIndex: 2,
    explanation:
      "混同行列はTP、FP、TN、FNの件数を表形式で示すもので、これらからAccuracy、Precision、Recall、F1スコアなどを算出できます。しかし最適な分類閾値は混同行列自体からは直接決定できず、ROC曲線やPR曲線の分析が必要です。",
  },
  {
    id: "ml-039",
    category: "データサイエンス力",
    question: "回帰モデルの評価指標において、MAE（平均絶対誤差）とRMSE（二乗平均平方根誤差）の比較として正しいものはどれか？",
    choices: [
      "MAEとRMSEは常に同じ値になる",
      "RMSEはMAEに比べて大きな誤差をより強く罰する性質がある",
      "MAEは負の値を取ることがある",
      "RMSEは外れ値に対してMAEより頑健である",
    ],
    correctIndex: 1,
    explanation:
      "RMSEは誤差を二乗してから平均し平方根を取るため、大きな誤差がより強く影響します。一方MAEは誤差の絶対値の平均であり、外れ値に対してRMSEよりロバストです。MSE（平均二乗誤差）はRMSEの二乗で、微分可能なため最適化の損失関数として使いやすい特長があります。",
  },
  {
    id: "ml-040",
    category: "データサイエンス力",
    question: "シルエットスコアの説明として正しいものはどれか？",
    choices: [
      "教師あり学習の分類精度を評価する指標",
      "クラスタリングの品質を評価する指標で、各データ点がどの程度適切なクラスタに属しているかを-1から1で示す",
      "回帰モデルの予測誤差を評価する指標",
      "データの次元数を評価する指標",
    ],
    correctIndex: 1,
    explanation:
      "シルエットスコアは各データ点について、同一クラスタ内の平均距離aと最近傍の他クラスタとの平均距離bから(b-a)/max(a,b)で計算されます。値が1に近いほどクラスタリングが適切、0に近いとクラスタ境界上、-1に近いと誤ったクラスタに割り当てられていることを示します。",
  },
  {
    id: "ml-041",
    category: "データサイエンス力",
    question: "Word2Vecの説明として正しいものはどれか？",
    choices: [
      "単語をワンホットベクトルとして表現する手法",
      "単語の意味的な関係を捉えた密なベクトル（分散表現）に変換する手法",
      "文書全体を1つのベクトルに変換する手法",
      "単語の出現頻度をカウントする手法",
    ],
    correctIndex: 1,
    explanation:
      "Word2Vecは単語を低次元の密なベクトル（分散表現・埋め込み）に変換するモデルです。CBOW（周辺語から中心語を予測）とSkip-gram（中心語から周辺語を予測）の2つのアーキテクチャがあります。「王 - 男 + 女 ≈ 女王」のような単語の意味的な関係をベクトル演算で捉えられます。",
  },
  {
    id: "ml-042",
    category: "データサイエンス力",
    question: "BERTの学習方法の特徴として正しいものはどれか？",
    choices: [
      "左から右への一方向のみで言語をモデル化する",
      "文中の一部の単語をマスクして予測するMasked Language Modelなどで双方向に事前学習する",
      "教師あり学習のみで事前学習する",
      "画像データを用いて事前学習する",
    ],
    correctIndex: 1,
    explanation:
      "BERT（Bidirectional Encoder Representations from Transformers）はMasked Language Model（ランダムにマスクした単語を文脈から予測）とNext Sentence Prediction（2文の連続性を予測）で双方向に事前学習を行います。GPTが左から右の一方向であるのに対し、BERTは両方向の文脈を同時に利用できます。",
  },
  {
    id: "ml-043",
    category: "データサイエンス力",
    question: "説明可能AI（XAI）の手法であるSHAPの特徴として正しいものはどれか？",
    choices: [
      "モデルの内部パラメータを直接可視化する手法",
      "ゲーム理論のシャープレイ値に基づき各特徴量の予測への貢献度を算出する手法",
      "モデルの精度を向上させるための特徴量選択手法",
      "モデルの学習過程を再現する手法",
    ],
    correctIndex: 1,
    explanation:
      "SHAP（SHapley Additive exPlanations）はゲーム理論のシャープレイ値を基に、各特徴量が個々の予測にどの程度貢献しているかを定量的に算出します。モデルに依存しない手法であり、LIMEが局所的な線形近似で説明するのに対し、SHAPは理論的に一貫した特徴量の重要度を提供します。",
  },
  {
    id: "ml-044",
    category: "データサイエンス力",
    question: "半教師あり学習の説明として正しいものはどれか？",
    choices: [
      "教師あり学習と教師なし学習を交互に行う手法",
      "少量のラベル付きデータと大量のラベルなしデータを組み合わせて学習する手法",
      "ラベルの半分を無視して学習する手法",
      "2つの異なるモデルを同時に学習させる手法",
    ],
    correctIndex: 1,
    explanation:
      "半教師あり学習は少量のラベル付きデータと大量のラベルなしデータを併用して学習する手法です。ラベル付けのコストが高い実務場面で有用です。自己学習（self-training）、ラベル伝播法、一貫性正則化などの手法があります。",
  },
  {
    id: "ml-045",
    category: "データサイエンス力",
    question: "ニューラルネットワークの活性化関数に関して、ReLU関数の利点はどれか？",
    choices: [
      "出力が常に0から1の範囲に収まるため確率として解釈しやすい",
      "計算が単純（max(0, x)）で勾配消失が起きにくく、学習が高速化する",
      "出力が-1から1の範囲で対称性がある",
      "多クラス分類の出力層に最も適している",
    ],
    correctIndex: 1,
    explanation:
      "ReLU（Rectified Linear Unit）はf(x) = max(0, x)と計算が非常に単純で、正の領域では勾配が1のため勾配消失が起きにくいです。sigmoidは出力が0-1で確率解釈に適し、softmaxは多クラス分類の出力層に使用されます。ReLUの負の領域で勾配が0になる「dying ReLU問題」を改善したLeaky ReLUなどの変種もあります。",
  },
  {
    id: "ml-046",
    category: "データサイエンス力",
    question: "ドロップアウト（Dropout）の仕組みとして正しいものはどれか？",
    choices: [
      "損失関数にペナルティ項を追加する正則化手法",
      "学習時にランダムにニューロンを無効化し、推論時は全ニューロンを使用する手法",
      "学習データからランダムにサンプルを削除する手法",
      "不要な層を削除してネットワークを軽量化する手法",
    ],
    correctIndex: 1,
    explanation:
      "ドロップアウトは学習時に各ニューロンを一定確率pでランダムに無効化（出力を0に）することで、特定のニューロンへの過度な依存を防ぐ正則化手法です。推論時は全ニューロンを使用し、出力に(1-p)を掛けて調整します。アンサンブル学習の近似として解釈することもできます。",
  },
  {
    id: "ml-047",
    category: "データサイエンス力",
    question: "早期打ち切り（Early Stopping）の仕組みとして正しいものはどれか？",
    choices: [
      "学習率が一定値以下になったら学習を停止する",
      "検証データの性能が改善しなくなった時点で学習を停止し、過学習を防ぐ",
      "訓練誤差が0になった時点で学習を停止する",
      "指定したエポック数に達したら必ず学習を停止する",
    ],
    correctIndex: 1,
    explanation:
      "早期打ち切りは学習の進行中に検証データでの性能（損失や精度）を監視し、改善が見られなくなった時点で学習を停止する手法です。訓練を続けると訓練データへの過学習が進むため、検証性能が最良の時点のモデルを採用します。patience（何エポック改善がなければ停止するか）が主要なパラメータです。",
  },
  {
    id: "ml-048",
    category: "データサイエンス力",
    question: "異常検知の手法としてIsolation Forestの考え方はどれか？",
    choices: [
      "正常データの分布を推定し、分布から外れるデータを異常とする",
      "ランダムな特徴量と閾値で分割を繰り返し、少ない分割回数で孤立するデータを異常とする",
      "k近傍法に基づき、近傍のデータとの距離が近いデータを異常とする",
      "オートエンコーダの復元誤差が小さいデータを異常とする",
    ],
    correctIndex: 1,
    explanation:
      "Isolation Forestはランダムに特徴量と分割値を選んでデータを再帰的に分割する木を複数構築し、少ない分割回数（短いパス長）で孤立するデータを異常とみなします。異常データは正常データより少なく特異なため早く孤立するという直感に基づいており、高次元データにも有効な手法です。",
  },
  {
    id: "ml-049",
    category: "データサイエンス力",
    question: "推薦システムにおける協調フィルタリングの説明として正しいものはどれか？",
    choices: [
      "アイテムの属性（ジャンル、価格等）に基づいて推薦する手法",
      "類似するユーザーの嗜好やアイテムへの評価パターンを利用して推薦する手法",
      "ルールベースで人手により推薦を作成する手法",
      "ランダムにアイテムを推薦する手法",
    ],
    correctIndex: 1,
    explanation:
      "協調フィルタリングは「似た嗜好を持つユーザーは似たアイテムを好む」という仮定に基づく推薦手法です。ユーザーベース（類似ユーザーの好みを参考）とアイテムベース（類似アイテムを推薦）の2種類があります。コンテンツベースフィルタリング（アイテム属性に基づく手法）と対比される概念です。",
  },
  {
    id: "ml-050",
    category: "データサイエンス力",
    question: "時系列分析におけるARIMAモデルの構成要素として正しいものはどれか？",
    choices: [
      "注意機構、再帰処理、畳み込みの3つ",
      "自己回帰（AR）、和分（I：差分による定常化）、移動平均（MA）の3つ",
      "平均、分散、自己相関の3つ",
      "トレンド、季節性、ノイズの3つ",
    ],
    correctIndex: 1,
    explanation:
      "ARIMA（p, d, q）モデルはAR（自己回帰：過去の値からの回帰）、I（和分：d回の差分で非定常系列を定常化）、MA（移動平均：過去の誤差項からの回帰）の3つの要素で構成されます。季節性を扱うSARIMAや、外生変数を加えたARIMAXなどの拡張もあります。",
  },
];
